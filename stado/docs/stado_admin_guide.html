<html><head><meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1"><title>Stado Administration Guide</title><meta name="generator" content="DocBook XSL Stylesheets V1.75.2"></head><body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF"><div class="book" title="Stado Administration Guide"><div class="titlepage"><div><div><h1 class="title"><a name="stado_admin_guide"></a><span class="productname">Stado<br></span> Administration Guide</h1></div></div><hr></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="chapter"><a href="#install">1. Installation</a></span></dt><dd><dl><dt><span class="sect1"><a href="#os">Operating System</a></span></dt><dd><dl><dt><span class="sect2"><a href="#kernel">Additional Linux Kernel Settings</a></span></dt><dt><span class="sect2"><a href="#java">Java</a></span></dt><dt><span class="sect2"><a href="#stado">Stado</a></span></dt><dt><span class="sect2"><a href="#database">Underlying Database</a></span></dt></dl></dd></dl></dd><dt><span class="chapter"><a href="#config">2. Stado Configuration</a></span></dt><dd><dl><dt><span class="sect1"><a href="#config_file">The stado.config File</a></span></dt><dd><dl><dt><span class="sect2"><a href="#config_sample">Sample stado.config File</a></span></dt></dl></dd><dt><span class="sect1"><a href="#init_stado">Initializing Stado</a></span></dt><dd><dl><dt><span class="sect2"><a href="#manual_mode">Manual Mode</a></span></dt></dl></dd><dt><span class="sect1"><a href="#start">Starting the Coordinator and Agents</a></span></dt><dd><dl><dt><span class="sect2"><a href="#start_coord">Coordinator</a></span></dt><dt><span class="sect2"><a href="#start_agents">Agents</a></span></dt></dl></dd><dt><span class="sect1"><a href="#creating_users">Creating User Databases</a></span></dt><dd><dl><dt><span class="sect2"><a href="#example">Example</a></span></dt></dl></dd><dt><span class="sect1"><a href="#testing_db">Testing the Database</a></span></dt><dt><span class="sect1"><a href="#start_db">Starting and Stopping Databases</a></span></dt><dt><span class="sect1"><a href="#drop_db">Dropping Databases</a></span></dt><dt><span class="sect1"><a href="#planning">Planning</a></span></dt><dt><span class="sect1"><a href="#unicode">Multi-Language and Unicode Support</a></span></dt><dt><span class="sect1"><a href="#ref">The stado.config Reference</a></span></dt><dd><dl><dt><span class="sect2"><a href="#server_settings">Server Settings</a></span></dt><dt><span class="sect2"><a href="#metadata_settings">Metadata Database Settings</a></span></dt><dt><span class="sect2"><a href="#jdbc_settings">JDBC and Pool Settings</a></span></dt><dt><span class="sect2"><a href="#under_settings">Configuration for Underlying Databases</a></span></dt><dt><span class="sect2"><a href="#datatypes">Data Types and Data Type Mapping</a></span></dt><dt><span class="sect2"><a href="#functions">Function Mapping</a></span></dt><dt><span class="sect2"><a href="#logging">Logging</a></span></dt></dl></dd></dl></dd><dt><span class="chapter"><a href="#privs">3. Users and Privileges</a></span></dt><dd><dl><dt><span class="sect1"><a href="#users">Users</a></span></dt><dt><span class="sect1"><a href="#privs">Privileges</a></span></dt></dl></dd><dt><span class="chapter"><a href="#backups">4. Redundancy, Backup and Recovery</a></span></dt><dd><dl><dt><span class="sect1"><a href="#redundancy">Redundancy</a></span></dt><dt><span class="sect1"><a href="#load_balancing">Load Balancing</a></span></dt><dt><span class="sect1"><a href="#backups">Backup &amp; Recovery</a></span></dt></dl></dd><dt><span class="chapter"><a href="#install">5. Installation</a></span></dt><dd><dl><dt><span class="sect1"><a href="#gs-cmdline">gs-cmdline</a></span></dt><dt><span class="sect1"><a href="#gs-createdb">gs-createdb</a></span></dt><dt><span class="sect1"><a href="#gs-createmddb">gs-createmddb</a></span></dt><dt><span class="sect1"><a href="#gs-dropdb">gs-dropdb</a></span></dt><dt><span class="sect1"><a href="#gs-agent">gs-agent</a></span></dt><dt><span class="sect1"><a href="#gs-dbstart">gs-dbstart</a></span></dt><dt><span class="sect1"><a href="#gs-dbstop">gs-dbstop</a></span></dt><dt><span class="sect1"><a href="#gs-server">gs-server</a></span></dt><dt><span class="sect1"><a href="#gs-shutdown">gs-shutdown</a></span></dt><dt><span class="sect1"><a href="#gs-loader">gs-loader and gs-impex</a></span></dt></dl></dd><dt><span class="chapter"><a href="#isolation">6. Isolation Levels and Locking</a></span></dt><dt><span class="chapter"><a href="#troubleshooting">7. Troubleshooting</a></span></dt><dd><dl><dt><span class="sect1"><a href="#install">Issues with Installation and Configuration</a></span></dt><dt><span class="sect1"><a href="#execution">Issues with Execution</a></span></dt></dl></dd><dt><span class="chapter"><a href="#appendices">8. Appendices</a></span></dt><dd><dl><dt><span class="sect1"><a href="#metadata_schema">Metadata Database Schema</a></span></dt></dl></dd></dl></div><div class="chapter" title="Chapter 1. Installation"><div class="titlepage"><div><div><h2 class="title"><a name="install"></a>Chapter 1. Installation</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#os">Operating System</a></span></dt><dd><dl><dt><span class="sect2"><a href="#kernel">Additional Linux Kernel Settings</a></span></dt><dt><span class="sect2"><a href="#java">Java</a></span></dt><dt><span class="sect2"><a href="#stado">Stado</a></span></dt><dt><span class="sect2"><a href="#database">Underlying Database</a></span></dt></dl></dd></dl></div><div class="sect1" title="Operating System"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="os"></a>Operating System</h2></div></div></div><p>
     Stado can run under Linux or any other platform that supports Java.
   </p><div class="sect2" title="Additional Linux Kernel Settings"><div class="titlepage"><div><div><h3 class="title"><a name="kernel"></a>Additional Linux Kernel Settings</h3></div></div></div><p>
       There are some additional kernel configuration values that should be 
       modified. The underlying database requires ample shared memory, so the
       <code class="literal">kernel.shmmax</code>, <code class="literal">kernel.shmall</code> and
       <code class="literal">kernel.sem</code> values should be increased. This can be 
       set in the <code class="literal">/etc/sysctl.conf</code> file. 
     </p><p>
       The value of <code class="literal">kernel.shmmax</code> refers to the maximum size
       of shared memory segments in bytes, while 
       <code class="literal">kernel.shmmall</code> is the total amount of shared memory 
       available. These values should be set fairly high; you can start with 
       50% of available memory and monitor the system to adjust.  If a lot of
       system paging occurs, lower this value. Conversely, increase it if there
       is still a lot of available memory afterwards.  
     </p><p>
       The value <code class="literal">kernel.shmni</code> is for the system wide maximum
       number of shared memory segments. 4096 is a reasonable value.
     </p><p>
       The kernel setting <code class="literal">kernel.sem</code> maps to four 
       parameters: <code class="literal">SEMMSL SEMMNS SEMOPM SEMMNI</code>
     </p><pre class="programlisting">
       SEMMSL: maximum num of semaphores per id 
       SEMMNS: maximum number of semaphores in system (SEMMNI*SEMMSL)
       SEMOPM: maximum num of ops per semop call 
       SEMMNI: maximum number of semaphore identifiers
     </pre><p>
       Sample values for 2 GB of shared memory to be set in 
       <code class="literal">/etc/sysctl.conf</code> (adjust <code class="literal">shmmax</code> 
       and <code class="literal">shmall</code>, depending on desired shared memory):
     </p><pre class="programlisting">
       kernel.shmmax = 68719476736
       kernel.shmmni = 4096
       kernel.shmall = 4294967296
       kernel.sem = 1000 128000 100 128
     </pre><p>
       After modifying the file, execute &#8220;<code class="literal">sysctl &#8211;p</code>&#8221; to have
       these values take effect.
     </p><div class="sect3" title="Number of Open Files"><div class="titlepage"><div><div><h4 class="title"><a name="open_files"></a>Number of Open Files</h4></div></div></div><p>
         Depending on your configuration, you may run into errors involving a 
         limit to the number of open files that your operating system allows 
         the user to have. This is particularly likely when you have several 
         nodes in the cluster. 
       </p><p>
         To change that, increase the limit of the number of files that can be 
         open by modifying the <code class="literal">/etc/security/limits.conf</code> 
         file, increasing the value for nofile. 
       </p><p>
         If you do not do this, you may encounter error messages like &#8220;unable 
         to send to nodes&#8221;.
       </p></div><div class="sect3" title="Read-Ahead"><div class="titlepage"><div><div><h4 class="title"><a name="read_ahead"></a>Read-Ahead</h4></div></div></div><p>
         In data warehousing, tables are often scanned entirely, so having the 
         operating system read ahead can significantly boost query times. You 
         can increase the read-ahead size for your RAID devices with the 
         blockdev command. For example:
       </p><pre class="programlisting">
         
           blockdev &#8211;-setra 16384 &lt;device&gt;
         
       </pre></div><div class="sect3" title="Access Time"><div class="titlepage"><div><div><h4 class="title"><a name="access_time"></a>Access Time</h4></div></div></div><p>
         Very often whenever files are accessed, the operating system will 
         update the last time of read or write access for bookkeeping. To turn
         off this extra unnecessary overhead in Linux, modify the 
         <code class="literal">/etc/fstab</code> file after you create your dedicated 
         data partitions, and add the &#8220;noatime&#8221; attribute.
       </p></div></div><div class="sect2" title="Java"><div class="titlepage"><div><div><h3 class="title"><a name="java"></a>Java</h3></div></div></div><p>
       This software requires the Java Runtime Environment 5, version 1.5.0_12
       or later. Earlier versions of the JRE may result in memory leaks that 
       over time result in an OutOfMemory exception. 
     </p><p>
       Stado has also been successfully tested with Java 6 update 18, and is
       recommended. 
     </p><p>
       If Stado was not installed via an installer that included a JRE, please 
       go to http://www.java.com/en/download/index.jsp to download a Java 
       Runtime Environment  Note that some Linux versions come with Java 
       already installed, but these will not necessarily work with Stado. For 
       example, the pre-installed version of Java on Ubuntu 7.10 causes the 
       Stado process to chew up CPU and is unresponsive.
     </p></div><div class="sect2" title="Stado"><div class="titlepage"><div><div><h3 class="title"><a name="stado"></a>Stado</h3></div></div></div><p>
       The instructions for installing Stado vary, depending on the target
       operating system.
     </p><p>
       We will discuss configuring the actual Stado system itself in the next
       chapter.
     </p><div class="sect3" title="Linux"><div class="titlepage"><div><div><h4 class="title"><a name="linux"></a>Linux</h4></div></div></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>
             If not already, change to user root:
           </p><pre class="programlisting">
             su &#8211;
           </pre></li><li class="listitem"><p>
             Create a user group stadogrp, if it does not already exist:
           </p><pre class="programlisting">
             groupadd stadogrp
           </pre></li><li class="listitem"><p>
             Create an operating system user stado:
           </p><pre class="programlisting">
             useradd -g stadogrp stado
           </pre></li><li class="listitem"><p>
             All the files will be installed under /usr/local/stado-[version]. 
             Extract the downloaded gzipped tar file to /usr/local/
           </p><pre class="programlisting">
             tar xvzf stado_[version].tar.gz &#8211;C /usr/local
           </pre><p>
             At this point, it will create the following subdirectories: bin, 
             lib, config, doc, license, and log. The bin directory contains 
             some scripts that are wrappers to make it easier to execute Stado 
             programs, which are all java-based. The lib directory contains jar
             libraries that are required by Stado. Configuration information 
             that must be customized is found in the 
             <code class="literal">stado.config</code> file in the config directory. 
             Finally, a log directory is created for containing the server log 
             files.
           </p></li><li class="listitem"><p>
             Set ownership of the files correctly:
           </p><pre class="programlisting">
             chown stado &#8211;R /usr/local/stado-[version]
             chgrp stado &#8211;R /usr/local/stado-[version]
           </pre></li><li class="listitem"><p>
             We only allow the stado user to execute programs, except for 
             cmdline. We also want to set other permissions:
           </p><pre class="programlisting">
             chmod 700 /usr/local/stado-[version]/bin/*.sh
             chmod 775 /usr/local/stado-[version]/log
             chmod 755 /usr/local/stado-[version]/bin/gs-cmdline.sh 
             chmod 600 /usr/local/stado-[version]/config/*
           </pre></li></ol></div><p>
         The Stado user and other users may want to reference this file in an 
         appropriate profile file, like <code class="literal">~/.bash_profile</code>.  
         These users should also be made part of the Stado group, if they want
         to execute anything other than cmdline. For most commands, it is 
         required that you execute them as the user stado.
       </p><div class="sect4" title="Stado Agents"><div class="titlepage"><div><div><h5 class="title"><a name="agents"></a>Stado Agents</h5></div></div></div><p>
           If you wish to achieve better scalability and performance by having 
           an agent run on each of the underlying nodes, repeat the procedure 
           on each node that will participate in the database cluster. 
         </p><p>
           By default, each node agent will run within the main coordinator 
           process. For better scalability and avoid having the coordinator 
           node become a bottleneck, you can move this out onto each of the 
           nodes, with each agent running as a separate process.
         </p><p>
           It is recommended to first configure a centralized version without 
           the agents running on the nodes and verify that the system is 
           working properly, before configuring the agents. It is easier to 
           isolate any configuration issues this way.
         </p></div></div></div><div class="sect2" title="Underlying Database"><div class="titlepage"><div><div><h3 class="title"><a name="database"></a>Underlying Database</h3></div></div></div><p>
       Stado uses PostgreSQL 9.1 or later as the underlying database on each of
       the nodes. The underlying database should be fully and properly 
       installed on all of the nodes that are going to make up the Stado 
       cluster. It is also recommended to install PostgreSQL on all of the
       nodes exactly the same way. 
     </p><p>
       It is important that your environment is set up properly so that Stado 
       can work with the underlying database and use its utilities. It is a 
       good idea to add the PostgeSQL bin directory to your 
       <code class="literal">PATH</code> environment variable, to allow access to all of
       its programs. You should add this to the appropriate profile file for 
       Stado, like <code class="literal">~stado/.bash_profile</code>, if not already 
       configured. For example:
     </p><pre class="programlisting">
       export PATH=/usr/local/pgsql/bin:$PATH
     </pre><p>
       If GeoSpatial queries will be used, PostGIS 1.5 needs to be installed
       in the database <code class="literal">template1</code>. Follow the PostGIS setup
       steps at http://postgis.refractions.net/documentation/manual-1.5/ch02.html#PGInstall
     </p><div class="sect3" title="Logging Considerations"><div class="titlepage"><div><div><h4 class="title"><a name="logging"></a>Logging Considerations</h4></div></div></div><p>
         Like other database systems, PostgreSQL uses logging for point in time
         recovery, called Write Ahead Logging (WAL). 
       </p><p>
         The location of these files in a subdirectory called 
         <code class="literal">pg_xlog</code> in the data directory (the data directory 
         is the one specified with initdb). Although it is not required, you 
         may want to consider keeping these files on a separate disk, for 
         performance reasons. This can be done by either setting up a symbolic
         link, or by creating a new disk partition and mounting it at 
         <code class="literal">pg_xlog</code>, below the data directory.
       </p></div><div class="sect3" title="Initializing Underlying System"><div class="titlepage"><div><div><h4 class="title"><a name="init"></a>Initializing Underlying System</h4></div></div></div><p>
         PostgreSQL requires execution of the <code class="literal">initdb</code> command
         for initialization. If you used an installer, you can skip this step. 
         Login as the user postgres, and execute a command like the one below.  
       </p><p>
         The -D option must be included to indicate the location of the data. 
         We recommend a dedicated device with redundancy, whether local with 
         RAID 10 or RAID 5, or attached via SAN. If the PostgreSQL installer 
         already prompted you for this and you configured it, you can skip 
         this step. 
       </p><p>
         In the example below, the data directory is initialized at /GSDATA.
       </p><pre class="programlisting">
         /usr/local/pgsql/bin/initdb &#8211;D /GSDATA
       </pre><p>
         The <code class="literal">initdb</code> command must be executed on each node 
         that will make up the Stado cluster.
       </p></div><div class="sect3" title="Network"><div class="titlepage"><div><div><h4 class="title"><a name="network"></a>Network</h4></div></div></div><p>
         We must configure each of the underlying database instances to 
         communicate with one another for the Stado cluster to function 
         properly.
       </p><p>
         With PostgreSQL by default, only local connections will be accepted.
         Since the instances need to work together, an additional configuration
         parameter must be set in the postgresql.conf file, 
         <code class="literal">listen_addresses</code>. It takes a comma-separated list 
         of host names or ip addresses, including wildcards.  For security, you
         should set this to just a list of the other nodes in the cluster. If 
         using monitoring utilities from other locations, you can specify 
         something broader, including *.
       </p><p>
         The next step is to configure the pg_hba.conf file, which is used to 
         determine which users and clients can connect to the database. The 
         file is found in the data directory specified by the initdb command 
         earlier. 
       </p><p>
         More detailed information about configuring the file can be found in 
         the PostgreSQL documentation, but we include an example entry below:
       </p><pre class="programlisting">
         # TYPE  DATABASE    USER        CIDR-ADDRESS          METHOD
           host  all         all         192.168.75.0/24       md5
       </pre><p>
         The above entry allows any connection from the 192.168.75.* subnet, 
         provided that the user name and password are valid, using the md5 
         authentication method. It is a good idea to put the nodes on its own
         subnet, with access to the underlying databases only occurring through
         Stado.
       </p></div><div class="sect3" title="Configuring the Underlying Database"><div class="titlepage"><div><div><h4 class="title"><a name="config_db"></a>Configuring the Underlying Database</h4></div></div></div><p>
         PostgreSQL offers many configuration and tuning options to help 
         database administrators improve the performance of their system for
         the particular environment that it is running in.  In this case, we
         want to tune the database for a decision support environment. 
       </p><p>
         Available configuration options can be found in a file named 
         <code class="literal">postgres.conf</code> in the data directory.  The most 
         important options that you&#8217;ll want to be concerned about appear below.
       </p><pre class="programlisting">
         shared_buffers = 512MB    
         maintenance_work_mem = 256MB
         work_mem = 128MB
         effective_cache_size = 2GB
         random_page_cost = 4
 
         wal_buffers = 64
         checkpoint_segments = 128    
         checkpoint_timeout = 900

         max_connections = 100
         default_statistics_target = 500
       </pre><p>
         More details about these options appear in the PostgreSQL 
         documentation. The parameters in the first group are the most 
         important, and should be adjusted based on the amount of memory that
         you have and number of users. Tuning can be difficult and may require
         trial and error to get the best results, depending on your 
         environment, the number of users, the schema, and the queries. 
       </p><p>
         We briefly discuss these parameters. 
       </p><p>
         The parameter <code class="literal">shared_buffers</code> is for the database&#8217;s 
         buffer cache. In OLTP systems, you normally want this to be as large 
         as possible (available system memory), but not exceeding 2.5GB.  For 
         data warehousing, it is best to set this according to trial and error 
         with your data. Sometimes it is surprisingly faster to run with a 
         smaller sized cache, such as 256MB. Note that Linux has its own file 
         system cache, so data can still be cached in memory, just not in the 
         database&#8217;s cache. This also means that double buffering can occur, 
         once in <code class="literal">shared_buffers</code>, and again in the file 
         system cache, making less than optimal use of available memory for 
         caching. Data warehousing often involves large sequential scans 
         anyway, and an overly large shared_buffers setting where a large 
         cache is managed may actually hurt performance.
       </p><p>
         The parameter <code class="literal">maintenance_work_mem</code> is used for
         creating indexes, foreign keys, and vacuum and analyze. You may want
         to consider setting this value much higher initially while loading up 
         the database and building indexes, and then lowering it later.
       </p><p>
         The parameter <code class="literal">work_mem</code> is used for operations like
         sorting and aggregation.  Setting this high can substantially improve 
         sort performance. As a result, we have increased the default from 1MB
         to 128MB here. Keep in mind that a single query may need multiple 
         <code class="literal">work_mem</code> allocations, and you may have multiple 
         concurrent users at the same time, so try not set 
         <code class="literal">work_mem</code> too high, or swapping may occur.
       </p><p>
         The PostgreSQL query planner is only influenced by 
         <code class="literal">effective_cache_size</code>; it does not actually 
         influence allocated memory. For OLTP systems, it is recommended that
         this is about 2/3 or RAM. The parameter 
         <code class="literal">random_page_cost</code> is the internal cost the optimizer
         uses for seek costing. While it depends on your system configuration,
         schema and queries, you will probably want to bias things towards
         sequential scans instead of index seeks. One way to do that is to 
         decrease <code class="literal">effective_cache_size</code> and increase 
         <code class="literal">random_page_cost</code>.
       </p><p>
         The second group of values is used for the Write Ahead Log, and can 
         impact performance in particular when loading the database.
       </p><p>
         The parameter <code class="literal">max_connections</code> determines how many
         simultaneous connections can connect to the PostgreSQL database. Stado
         creates pools of connections to the database, and you want to make 
         sure you have enough connections. The exact amount for this to use may
         be influenced by how you configure the Stado stado.config file 
         (described later), but it is a good idea to make sure that this is set
         sufficiently high.  Note that if you use multiple logical nodes per 
         same physical server, you will need to increase this; one pool will be
         used for each logical node, even though they refer to the same 
         PostgreSQL instance. Also, additional connections are needed for: row
         shipping during some queries; a coordinator connection pool; a 
         connection to the metadata database. If connections are an issue, you
         can increase <code class="literal">max_connections</code> and consider 
         decreasing the min and max pool size.
       </p></div><div class="sect3" title="Starting the Underlying Database Server Process"><div class="titlepage"><div><div><h4 class="title"><a name="start_db"></a>Starting the Underlying Database Server Process</h4></div></div></div><p>
         PostgreSQL offers the <code class="literal">pg_ctl</code>  wrapper to start the
         postmaster and run it as a background process. For example, if 
         <code class="literal">initdb</code> used <code class="literal">/GSDATA</code> as the 
         location of PostgreSQL data, you can start the postmaster process
         using the command below:
       </p><pre class="programlisting">
         /usr/local/pgsql/bin/pg_ctl start -D /GSDATA -l logfile
       </pre><p>
         The -l option allows you to specify a log file for the PostgreSQL log.
       </p></div><div class="sect3" title="Database User"><div class="titlepage"><div><div><h4 class="title"><a name="db_user"></a>Database User</h4></div></div></div><p>
         A database user must be created on each instance that will be used by
         Stado for connecting to the databases.  This single user will always 
         be used for connecting to the underlying database. The username and 
         password will be required later when configuring Stado&#8217;s 
         <code class="literal">stado.config</code> file, so please make note of it. You
         should use the same username and password on all instances.
       </p><p>
         In the example below, we create a database user named stado. Note that
         this is a database user and not operating system user. Stado will 
         later use this user when connecting to the individual database 
         instances running on the nodes.
       </p><pre class="programlisting">
	 /usr/local/pgsql/bin/createuser &#8211;d &#8211;E stado &#8211;U postgres -P
       </pre><p>
         After executing this, it will prompt you for a password, and ask you
         to retype it. Please note this password for later. It may also give 
         you a third password prompt. This is because of the -U option, where
         we are executing the command as the database super user that you used 
         when you configured the underlying database, in this case user 
         <code class="literal">postgres</code>.
       </p><p>
         Repeat the execution of <code class="literal">createuser</code> on each node.
       </p><div class="sect4" title="Coordinator"><div class="titlepage"><div><div><h5 class="title"><a name="coordinator"></a>Coordinator</h5></div></div></div><p>
           When using PostgreSQL with authentication, a password will be 
           required for authentication.  Stado makes use of PostgreSQL command
           line utilities, so we create a <code class="literal">.pgpass</code> file in 
           the stado user&#8217;s home directory. This is used by PostgreSQL to
           provide passwords to connect to other servers. This only needs to be
           done on the coordinator. 
         </p><p>
           Login as user <code class="literal">stado</code>.
         </p><p>
           The file&#8217;s access must be restricted to the user, in this case 
           <code class="literal">stado</code>.  After creating the file, you need to 
           restrict access via <code class="literal">chmod 600 ~stado/.pgpass</code>.
         </p><p>
           It is important that you setup <code class="literal">.pgpass</code>, otherwise,
           executing Stado scripts like <code class="literal">gs-createmddb.sh</code> will
           appear to hang, because the particular PostgreSQL utility will be 
           trying to prompt for a password.
         </p><p>
           The lines in the file are to appear in the format:
         </p><pre class="programlisting">
           hostname:port:database:username:password
         </pre><p>
           Wildcards may be used. An example appears below:
         </p><pre class="programlisting">
           *:*:*:stado:password
         </pre><p>
           where password is the password we used with 
           <code class="literal">createuser</code>. The Stado process that will later run
           under the <code class="literal">stado</code> user can now connect to all nodes 
           and use PostgreSQL utilities without requiring a password from the  
           user. Note that user &#8220;<code class="literal">stado</code>&#8221; here is a database 
           user, not an operating system user.
         </p></div></div><div class="sect3" title="Verify"><div class="titlepage"><div><div><h4 class="title"><a name="verify"></a>Verify</h4></div></div></div><p>
         Before proceeding to configuring Stado, it is a good idea to verify 
         that the underlying databases and network have been installed and 
         configured properly. Doing this now will help make troubleshooting 
         your Stado installation easier by eliminating the likelihood of 
         configuration issues with the underlying database. 
       </p><p>
         Verification can be done by creating a test database on each, by 
         running <code class="literal">createdb</code> from the coordinator. 
       </p><pre class="programlisting">
         /usr/local/pgsql/bin/createdb &#8211;h node1 &#8211;U stado test
       </pre><p>
         Here, node1 is the host name or IP address of one of the nodes that 
         will be in the Stado cluster. Run this command from the coordinator 
         node for each node. We use the database user <code class="literal">stado</code>
         that we previously created and verify login and create privilege.
       </p><p>
         If there is a problem, verify that the 
         <code class="literal">postgresql.conf</code> file has 
         <code class="literal">listen_addresses</code> set to allowable hosts, that the 
         node has a valid <code class="literal">pg_hba.conf</code> file, and that the 
         <code class="literal">postgres</code> user on the coordinator has a valid 
         <code class="literal">.pgpass</code> (or pgpass.conf) file. Note that if you 
         modify the <code class="literal">pg_hba.conf</code> file, you must restart 
         postmaster.
       </p></div></div></div></div><div class="chapter" title="Chapter 2. Stado Configuration"><div class="titlepage"><div><div><h2 class="title"><a name="config"></a>Chapter 2. Stado Configuration</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#config_file">The stado.config File</a></span></dt><dd><dl><dt><span class="sect2"><a href="#config_sample">Sample stado.config File</a></span></dt></dl></dd><dt><span class="sect1"><a href="#init_stado">Initializing Stado</a></span></dt><dd><dl><dt><span class="sect2"><a href="#manual_mode">Manual Mode</a></span></dt></dl></dd><dt><span class="sect1"><a href="#start">Starting the Coordinator and Agents</a></span></dt><dd><dl><dt><span class="sect2"><a href="#start_coord">Coordinator</a></span></dt><dt><span class="sect2"><a href="#start_agents">Agents</a></span></dt></dl></dd><dt><span class="sect1"><a href="#creating_users">Creating User Databases</a></span></dt><dd><dl><dt><span class="sect2"><a href="#example">Example</a></span></dt></dl></dd><dt><span class="sect1"><a href="#testing_db">Testing the Database</a></span></dt><dt><span class="sect1"><a href="#start_db">Starting and Stopping Databases</a></span></dt><dt><span class="sect1"><a href="#drop_db">Dropping Databases</a></span></dt><dt><span class="sect1"><a href="#planning">Planning</a></span></dt><dt><span class="sect1"><a href="#unicode">Multi-Language and Unicode Support</a></span></dt><dt><span class="sect1"><a href="#ref">The stado.config Reference</a></span></dt><dd><dl><dt><span class="sect2"><a href="#server_settings">Server Settings</a></span></dt><dt><span class="sect2"><a href="#metadata_settings">Metadata Database Settings</a></span></dt><dt><span class="sect2"><a href="#jdbc_settings">JDBC and Pool Settings</a></span></dt><dt><span class="sect2"><a href="#under_settings">Configuration for Underlying Databases</a></span></dt><dt><span class="sect2"><a href="#datatypes">Data Types and Data Type Mapping</a></span></dt><dt><span class="sect2"><a href="#functions">Function Mapping</a></span></dt><dt><span class="sect2"><a href="#logging">Logging</a></span></dt></dl></dd></dl></div><p>
    This chapter discusses how to configure Stado, including creating and using
    databases. The first part assumes a first time configuration after 
    installation, and the chapter concludes with more information about 
    multi-language support and an <code class="literal">stado.config</code> file 
    reference.
  </p><p>
    If you have not done so already, login as the <code class="literal">stado</code> user
    to modify. 
  </p><div class="sect1" title="The stado.config File"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="config_file"></a>The stado.config File</h2></div></div></div><p>
      A configuration file must be created that will determine how the Stado 
      server is run.  When the Stado server is run, it reads from a file named
      <code class="literal">stado.config</code> in the <code class="literal">config</code> 
      directory for system defaults. The file needs to be configured properly 
      to initialize the metadata database and user-created databases.
    </p><p>
      There are a myriad of options, but few options need to be changed in 
      practice, those being the host or IP of the nodes, underlying database 
      username and password, and database port.
    </p><p>
      Permissions for <code class="literal">stado.config</code> should be set to be 
      readable only by the <code class="literal">stado</code> user, since the file 
      contains username and password information for connecting to the 
      underlying databases.
    </p><p>
      The options for <code class="literal">xdb.metadata.*</code> determine where the
      metadata database resides. The metadata database contains information 
      about all of the user-created databases and schema info like tables, 
      columns, data types, indexes, and constraints. Make sure that the 
      <code class="literal">xdb.metadata</code> values are set properly, before trying
      to execute <code class="literal">gs-createmddb</code>, which will create the 
      metadata database. 
    </p><p>
      This <code class="literal">stado.config</code> file is also where you define the 
      nodes that are used in the Stado cluster, specifying the host or IP 
      address of each node. The username and password should be set to the same
      values as those you used when you created the database user earlier 
      (createuser with PostgreSQL).
    </p><p>
      The included default <code class="literal">stado.config</code> file contains the 
      most important options you may want to change. A detailed reference of 
      all of the available configuration options appears at the end of this 
      chapter, along with descriptions of mapping data types and defining and
      overriding SQL functions.
    </p><div class="sect2" title="Sample stado.config File"><div class="titlepage"><div><div><h3 class="title"><a name="config_sample"></a>Sample stado.config File</h3></div></div></div><p>
        To give a better idea of what a real <code class="literal">stado.config</code> 
        file looks like, a sample one appears below for a 4 node system. In 
        addition, a sample <code class="literal">stado.config</code> is found in the 
        <code class="literal">config</code> directory of your installation.
      </p><p>
        Note that some lines contain template variables that are enclosed with 
        curly braces, like <code class="literal">{dbhost}</code> and 
        <code class="literal">{database}</code>. These are dynamically substituted by the
        Stado server per database as needed- there is no need for you to 
        replace these here.
      </p><p>
        Be sure and modify the username and password information properly for 
        the underlying databases, as well as the hostname or IP address of each
        node in the database for <code class="literal">xdb.node.1.dbhost</code> through 
        <code class="literal">xdb.node.n.dbhost</code>. Also, if logging is desired, 
        modify the File parameter of each logger to be an absolute path to the 
        desired target file location.
      </p><p>
        The example below is for a four-node system. Note that you can use the 
        same host or IP address for all if you would like to create a &#8220;cluster&#8221;
        on a single system to just familiarize yourself with Stado. It will 
        assign a unique database name to each &#8220;node,&#8221; creating 4 underlying 
        databases. Also, you may choose to create fewer than 4 nodes if you 
        wish. Just change the <code class="literal">xdb.nodecount</code> and comment out
        or remove the appropriate <code class="literal">xdb.node.n.dbhost</code> entries.
      </p><p>
        In this file four different logs are referenced, as can be seen by the
        log4j properties. There is a main server log, a query log (to log 
        SELECT statements), and a long query log (for logging long SELECT 
        statements).
      </p><pre class="programlisting">
        ###########################################################################
        # stado.config
        #
        # Stado configuration file
        ###########################################################################


        ###
        ### Server settings
        ###

        xdb.port=6453
        xdb.maxconnections=10


        ###
        ### Node &amp; JDBC Pool configuration
        ### 

        ### Set defaults for all nodes and MetaData database. 
        ### These can be overriden.
        ### Note that {dbhost} and {database} are template variables
        ### that will be substituted dynamically per database

        xdb.default.dbusername=stado
        xdb.default.dbpassword=password

        ### Connection thread defaults for each node
        ### Note that these are pooled, so the number of clients connected 
        ### to the Stado server can be greater than pool size.

        xdb.default.threads.pool.initsize=5
        xdb.default.threads.pool.maxsize=10


        ### Connectivity for MetaData database

        xdb.metadata.database=XDBSYS
        xdb.metadata.dbhost=localhost

        ### The number of nodes in cluster

        xdb.nodecount=4

        ### Individual node info
        ### Set these to hostname or IP addresses of nodes

        xdb.node.1.dbhost=node1
        xdb.node.2.dbhost=node2
        xdb.node.3.dbhost=node3
        xdb.node.4.dbhost=node4

        ### Designate coordinator node
        ### In practice, the coordinator node should be the node where
        ### the Stado database is running.

        xdb.coordinator.node=1


        ###
        ### Logging Settings
        ###

        ### The log4j library is used. 
        ### More info at http://logging.apache.org/log4j/docs/

        # rootLogger. Log warnings and errors.
        log4j.rootLogger=WARN, console

        # Define other characteristics for console log
        log4j.appender.console=org.apache.log4j.RollingFileAppender
        log4j.appender.console.maxFileSize=500KB
        log4j.appender.console.maxBackupIndex=10
        log4j.appender.console.layout=org.apache.log4j.PatternLayout
        log4j.appender.console.layout.ConversionPattern=%d{ISO8601} - %-5p %m%n
        log4j.appender.console.File=/usr/local/stado-2.0/log/console.log

        # Log Server messages to the console logger
        log4j.logger.Server=ALL, console

        # Query logger.
        # This logs all queries sent to the database. 
        log4j.logger.query=INFO, QUERY
        log4j.appender.QUERY=org.apache.log4j.RollingFileAppender
        log4j.appender.QUERY.File=/usr/local/stado-2.0/log/query.log
        log4j.appender.QUERY.maxFileSize=500KB
        log4j.appender.QUERY.maxBackupIndex=10
        log4j.appender.QUERY.layout=org.apache.log4j.PatternLayout
        log4j.appender.QUERY.layout.ConversionPattern=%d{ISO8601} - %m%n

        # Uncomment this if you would like other SQL commands other
        # than SELECT to be logged in the query logger as well 
        # (e.g. INSERT, UPDATE, DELETE).

        #log4j.logger.command=INFO, QUERY

        # A separate "long query" log may be defined to separately log queries
        # that appear to be be taking a long time.
        # Specify the threshold in seconds at which queries will show up in the 
        # long query log.
        xdb.longQuerySeconds=300

        log4j.logger.longquery=INFO, LONGQUERY
        log4j.appender.LONGQUERY=org.apache.log4j.RollingFileAppender
        log4j.appender.LONGQUERY.File=/usr/local/stado-2.0/log/longqry.log
        log4j.appender.LONGQUERY.maxFileSize=500KB
        log4j.appender.LONGQUERY.maxBackupIndex=10
        log4j.appender.LONGQUERY.layout=org.apache.log4j.PatternLayout
        log4j.appender.LONGQUERY.layout.ConversionPattern=%d{ISO8601} - %m%n

        # activity logger.
        # This logs all queries sent to the database. 
        log4j.logger.activity=INFO, activity
        log4j.appender.activity=org.apache.log4j.RollingFileAppender
        log4j.appender.activity.File=/usr/local/stado-2.0/log/activity.log
        log4j.appender.activity.maxFileSize=10MB
        log4j.appender.activity.maxBackupIndex=10
        log4j.appender.activity.layout=org.apache.log4j.PatternLayout
        log4j.appender.activity.layout.ConversionPattern=%d{ISO8601} - %m%n
      </pre><p>
        A request is determined to be &#8220;long&#8221; based on another 
        <code class="literal">stado.config</code> value, 
        <code class="literal">xdb.longQuerySeconds</code>, which should be set to the
        number of seconds at which point it will be logged in the LONGQUERY 
        log.
      </p></div></div><div class="sect1" title="Initializing Stado"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="init_stado"></a>Initializing Stado</h2></div></div></div><p>
     To initialize the Stado cluster, the metadata database and an 
     administrative user must be created.
   </p><p>
     First, it is a good idea to add the PostgreSQL bin directory to your 
     <code class="literal">PATH</code> environment variable, to allow access to all of 
     its programs. You may want to also add this to the appropriate profile 
     like <code class="literal">~stado/.bash_profile</code> Example:
   </p><pre class="programlisting">
     export PATH=/usr/local/pgsql/bin:$PATH
   </pre><p>
     Before creating any user-defined databases, we must first create the 
     metadata database to contain information about the user-created databases.
     Once it is created, user-created databases and all of their corresponding
     information about tables and columns, etc., will be stored there.
   </p><p>
     In addition, we need to create an administrative user for Stado. Note that
     users in Stado are separate from the users used in PostgreSQL. Stado will
     always use the same user specified in <code class="literal">stado.config</code> to
     communicate with the underlying PostgreSQL databases. This is completely 
     separate from the users that are defined to interact with the Stado 
     cluster.
   </p><p>
     For both of these tasks, use the <code class="literal">gs-createmddb.sh</code> 
     command. It creates the required actual database on the underlying node,
     creates all needed tables, and creates an administrative user.  The exact 
     schema of the metadata database can be seen in the appendix. 
   </p><p>
     This relies on configuration values stored in the 
     <code class="literal">stado.config</code> file, so be sure that it is set properly. 
     Also, refer to the command reference in the next chapter that discusses 
     <code class="literal">gs-createmddb</code>. That means that you set all of the
     <code class="literal">xdb.metadata.*</code> properties as how you want them, and 
     that <code class="literal">gs-createmddb</code> will use these as your desired 
     settings. The username and password used should be valid and have 
     permission to create new databases and tables. You can use the username 
     and password created earlier.
   </p><p>
     If everything was setup properly in <code class="literal">stado.config</code>, you 
     are ready to execute <code class="literal">gs-createmddb.sh</code>. To create the 
     metadata database and create an initial user at the Stado level named 
     &#8220;admin&#8221; with the password &#8220;secret&#8221;:
   </p><pre class="programlisting">
     gs-createmddb.sh &#8211;u admin &#8211;p secret
   </pre><p>
     If -p is left off, the user will be prompted for a password.
   </p><div class="sect2" title="Manual Mode"><div class="titlepage"><div><div><h3 class="title"><a name="manual_mode"></a>Manual Mode</h3></div></div></div><p>
       You can also choose to create the metadata database manually with the 
       &#8211;m option, instead of having <code class="literal">gs-createmddb</code> do it for
       you. Instructions for doing this with PostgreSQL appear below. (Skip 
       this section if you created the metadata database successfully in the 
       previous section.)
     </p><p>
       If a database user for the underlying databases was not created in the 
       previous section, you should do so now. 
     </p><p>
       Next, create the database named <code class="literal">XDBSYS</code>, as designated
       in the <code class="literal">stado.config</code> file as the metadata database by 
       using the PostgreSQL command <code class="literal">createdb</code>.
     </p><pre class="programlisting">
       createdb XDBSYS -U stado
     </pre><p>
       Now, initialize the Stado metadata database. Note that &#8211;m is used here, 
       indicating that the physical database already exists; we just need to 
       initialize it and create the metadata tables in it.  Make sure a valid 
       username and password are set in the <code class="literal">xdb.metadata</code> 
       options of the <code class="literal">stado.config</code> file for the underlying 
       database. Also, pass in a Stado administrative username and password to
       create:
     </p><pre class="programlisting">
       gs-createmddb.sh &#8211;m &#8211;u admin &#8211;p secret
     </pre><p>
       Now the metadata database is ready, which can be verified using the 
       PostgreSQL command psql:
     </p><pre class="programlisting">
       psql -U stado -d XDBSYS &#8211;h 127.0.0.1
     </pre><p>
       Note that when using <code class="literal">psql</code> with Stado, you must 
       include the  -h option for host, even if it is local to force it to 
       use a socket connection.
     </p><p>
       You should plan on backing up the metadata database regularly. Whereas
       with other databases, an incremental backup may make the most sense, 
       the metadata database will be relatively small, so a complete backup 
       should be done.
     </p></div></div><div class="sect1" title="Starting the Coordinator and Agents"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="start"></a>Starting the Coordinator and Agents</h2></div></div></div><div class="sect2" title="Coordinator"><div class="titlepage"><div><div><h3 class="title"><a name="start_coord"></a>Coordinator</h3></div></div></div><p>
        We are now ready to start the <code class="literal">gs-server</code> process so 
        that we can create user databases. <code class="literal">gs-server</code> can be
        started with no arguments if no databases have been created yet:
      </p><pre class="programlisting">
	gs-server.sh
      </pre><p>
        This will start the server in the background. If there is a problem 
        with <code class="literal">gs-server</code>, please check the log files in the 
        log directory and verify the configuration in 
        <code class="literal">stado.config</code>.  Note that when executing the 
        <code class="literal">gs-server</code> process, you may need to modify the 
        parameters that Java uses, increasing the maximum amount of memory 
        specified in the <code class="literal">gs-server.sh</code> launch script, 
        depending on your requirements and system configuration.
      </p><p>
        When executing <code class="literal">gs-server</code> in the future, you can 
        include a list of previously created databases to bring online with 
        the -d option. That way, you will not need to separately execute 
        <code class="literal">gs-dbstart</code>.
      </p><pre class="programlisting">
	gs-server.sh &#8211;d xtest
      </pre></div><div class="sect2" title="Agents"><div class="titlepage"><div><div><h3 class="title"><a name="start_agents"></a>Agents</h3></div></div></div><p>
        If you installed and configured the cluster to use Stado Agents, you 
        will want to start the agents on all of the nodes. Perform this as user
        <code class="literal">stado</code>.
      </p><p>
        The Stado agent is started by calling the 
        <code class="literal">gs-agent.sh</code> wrapper script in the Stado 
        <code class="literal">bin</code> directory. It expects the &#8211;n argument, followed 
        by the designated node number this will act as in the cluster. Example:
      </p><pre class="programlisting">
	gs-agent.sh &#8211;n 4
      </pre><p>
        We recommend you start the server on the coordinator first 
        (<code class="literal">gs-server.sh</code>), before starting the agents. If the 
        <code class="literal">gs-server</code> process is stopped and restarted, it 
        should reestablish connections with the running agents. Similarly, if 
        an agent is stopped and restarted, <code class="literal">gs-server</code> will 
        detect that and reestablish a connection.
      </p><p>
        <code class="literal">gs-server</code> will log the event that an agent has 
        successfully connected to it, so if there is a problem in creating and 
        using databases, please read the coordinator logs to pinpoint the 
        source of the problem.
      </p></div></div><div class="sect1" title="Creating User Databases"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="creating_users"></a>Creating User Databases</h2></div></div></div><p>
       Now that the metadata database has been created and 
       <code class="literal">gs-server</code> is executing, you can create your own 
       databases. 
     </p><p>
       First, configure the individual nodes in the 
       <code class="literal">stado.config</code> file that you will be using if you have
       not already. You should have also installed the underlying database such
       as PostgreSQL 9.1 on all of those nodes, with the database server 
       running. Note that it is a good idea to have all of the nodes installed
       and configured exactly the same way to make administration easier. If 
       you make any changes to <code class="literal">stado.config</code>, you will need
       to restart <code class="literal">gs-server</code>.
     </p><p>
       It should also be pointed out that you could also have a system where 
       one of the nodes in the Stado system both participates as a member of
       user database nodes as well as contains the metadata database.
     </p><p>
       You create a database by using the <code class="literal">gs-createdb.sh</code> 
       utility. When a database is created, it adds the appropriate information
       to the metadata database. The <code class="literal">gs-createdb.sh</code> command 
       will also try and create the database on the underlying nodes if you 
       wish, which is recommended. Otherwise, use the -m (manual) option, which
       will only update the metadata database information without trying to 
       create any databases on the nodes.
     </p><p>
       See the <code class="literal">gs-createdb</code> command in the section of the 
       Command Reference section of this document for more information. 
     </p><div class="sect2" title="Example"><div class="titlepage"><div><div><h3 class="title"><a name="example"></a>Example</h3></div></div></div><p>
        We show two examples.  
      </p><p>
        The first example will create a Stado database named 
        <code class="literal">xtest</code>. The physical underlying databases will be 
        named xtestN1, xtestN2, xtestN3, and xtestN4 on the nodes, 
        corresponding to their node numbers.
      </p><pre class="programlisting">
        gs-createdb.sh -d xtest -u admin -p &lt;password&gt; -n 1,2,3,4
      </pre><p>
        Note that if you are prompted by a password even with &#8211;p, it is the 
        underlying tool, <code class="literal">psql</code> that is prompting you for a 
        password. This means you are executing <code class="literal">createdb</code> 
        under a user where a trusted PostgreSQL environment has not been 
        configured. Be sure that it is configured for user 
        <code class="literal">stado</code>, and execute the command as user 
        <code class="literal">stado</code>.
      </p><p>
        <span class="bold"><strong>Manual mode</strong></span>
      </p><p>
        If desired, the database can also be set up by hand, where the 
        databases are first created on the individual nodes using PostgreSQL&#8217;s
        <code class="literal">createdb</code> command. Care needs to be taken to name 
        them with the desired database name followed by &#8220;N&#8221; and the node number
        (&lt;dbname&gt;N1 on node 1, &lt;dbname&gt;N2 on node 2, etc.).  Once
        that is done, <code class="literal">gs-createdb.sh</code> can be called using the
        &#8220;-m&#8221; option to wire it up and update the metadata information.
      </p><pre class="programlisting">
        gs-createdb.sh -d xtest -u admin -p &lt;password&gt; -n 1,2,3,4 -m
      </pre></div></div><div class="sect1" title="Testing the Database"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="testing_db"></a>Testing the Database</h2></div></div></div><p>
       Once you have successfully created a database, you are ready to test 
       using the command line utility. 
     </p><p>
       Note that <code class="literal">gs-server</code> will automatically bring the 
       created database online and accept connections to it when you execute
       <code class="literal">gs-createdb.sh</code>. 
     </p><p>
       With the server running ok, execute <code class="literal">gs-cmdline.sh</code>, 
       specifying a database and valid username and password, such as:
     </p><pre class="programlisting">
       gs-cmdline.sh -d xtest -u admin -p &lt;password&gt;
     </pre><p>
       If you were able to connect ok you should receive a command prompt like
       the following:
     </p><pre class="programlisting">
       Stado-&gt;
     </pre><p>
       Try creating a table. The following command creates a table mytable1 and
       specifies that rows should be partitioned according to the column col1:
     </p><pre class="programlisting">
       CREATE TABLE mytable1 (col1 INT) PARTITIONING KEY col1 ON ALL;
     </pre><p>
       Try and insert some data:
     </p><pre class="programlisting">
	INSERT INTO mytable1 VALUES (1);
	INSERT INTO mytable1 VALUES (2);
     </pre><p>
       Select:
     </p><pre class="programlisting">
	SELECT * FROM mytable1;
     </pre><p>
       If everything looks ok, you can drop the table:
     </p><pre class="programlisting">
	DROP TABLE mytable1;
     </pre></div><div class="sect1" title="Starting and Stopping Databases"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="start_db"></a>Starting and Stopping Databases</h2></div></div></div><p>
       The commands gs-dbstart and gs-dbstop communicate with the gs-server
       process and can be used to bring Stado databases online or offline.
     </p><p>
       Example:
     </p><pre class="programlisting">
	gs-dbstart.sh &#8211;d xtest &#8211;u admin &#8211;p &lt;password&gt;
	gs-dbstop.sh &#8211;d xtest &#8211;u admin &#8211;p &lt;password&gt;
     </pre></div><div class="sect1" title="Dropping Databases"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="drop_db"></a>Dropping Databases</h2></div></div></div><p>
       You can drop databases using the dropdb command. 
     </p><p>
       If the database is online, dropdb will fail, so you should first bring 
       it offline with <code class="literal">gs-dbstop</code>:
     </p><pre class="programlisting">
	gs-dbstop.sh &#8211;d xtest &#8211;u admin &#8211;p &lt;password&gt;
     </pre><p>
       An example for dropping the xtest database appears below:
     </p><pre class="programlisting">
       gs-dropdb.sh -d xtest -u admin -p &lt;password&gt;
     </pre><p>
       It will attempt to drop the databases on the underlying nodes, as well 
       as clean out any metadata information in the XDBSYS database. Please 
       see dropdb in the Command Reference section of this document for more 
       information.
     </p><p>
       If dropping fails for some reason, you may want to try again with &#8220;-f&#8221;
      (force) option to continue and try and remove all metadata information 
      from the metadata database, even if it failed to drop a database on a 
      node.
     </p></div><div class="sect1" title="Planning"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="planning"></a>Planning</h2></div></div></div><p>
       You are now ready to create your own databases. Please refer to 
       important information in the Planning Guide for important information
       regarding determining your database schema and partitioning strategies
       before creating tables. A poorly thought out schema will result in less
       than optimal performance.
     </p></div><div class="sect1" title="Multi-Language and Unicode Support"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="unicode"></a>Multi-Language and Unicode Support</h2></div></div></div><p>
       Stado supports international character sets, provided the chosen 
       underlying database supports it as well and is configured properly. 
       For the current version, however, the Stado Metadata database does not 
       support international identifiers, so all object names such as tables 
       and columns must be standard identifiers using single-byte characters.
     </p><p>
       The following steps must be done in order to configure and support this 
       properly
     </p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p>
           The underlying database needs to be configured properly. In 
           PostgreSQL, unicode is enabled by default.
         </p></li><li class="listitem"><p>
           The JDBC Driver for the underlying database that Stado uses may 
           require additional parameters.
        </p></li><li class="listitem"><p>
           The Stado server must be configured. If you intend to use 
           international characters from some specific character set, you can
           specify its name in <code class="literal">stado.config</code> configuration 
           file, e.g.:
         </p></li></ol></div><pre class="programlisting">
       xdb.charset=windows-1252
     </pre><p>
       The default for xdb.charset is ISO-8859-1.
     </p><p>
       If Unicode is desired, including support for various clients using 
       different character sets, then add the following to the stado.config 
       file:
     </p><pre class="programlisting">
       xdb.unicode=yes
     </pre></div><div class="sect1" title="The stado.config Reference"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="ref"></a>The stado.config Reference</h2></div></div></div><p>
       If you need to customize your particular installation, you can change 
       the <code class="literal">stado.config</code> file.  
     </p><p>
       A table appears on the following pages describing all of the possible 
       configuration options in <code class="literal">stado.config</code>. 
     </p><div class="sect2" title="Server Settings"><div class="titlepage"><div><div><h3 class="title"><a name="server_settings"></a>Server Settings</h3></div></div></div><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td>
               <p><span class="bold"><strong>Configuration Value</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Default</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Description</strong></span></p>
            </td></tr><tr><td>
               <p>log4j.configuration</p>
            </td><td>
               <p></p>
            </td><td>
               <p>
                 Optional configuration file for logging preferences in log4j 
                 format. Alternatively, configuration properties may also be 
                 specified directly in the stado.config file. More information 
                 about log4j appears later in this chapter.
               </p>
            </td></tr><tr><td>
               <p>xdb.coordinator.node</p>
            </td><td>
               <p></p>
            </td><td>
               <p>
                 The node to use for combining results from underlying nodes. 
                 In practice, it is the node that corresponds to where the 
                 Stado server is running, whether or not it is a dedicated 
                 coordinator or not.
               </p>
            </td></tr><tr><td>
               <p>xdb.longQuerySeconds</p>
            </td><td>
               <p>300</p>
            </td><td>
               <p>
                 The threshold in number of seconds at which a query is 
                 determined to be a long running query, and logged in the 
                 long query log, if enabled. 
               </p>
            </td></tr><tr><td>
               <p>xdb.maxconnections</p>
            </td><td>
               <p>50</p>
            </td><td>
               <p>Maximum number of client connections to Stado to allow at a time.</p>
            </td></tr><tr><td>
               <p>xdb.nodecount</p>
            </td><td>
               <p></p>
            </td><td>
               <p>The number of underlying nodes in the Stado cluster</p>
            </td></tr><tr><td>
               <p>xdb.port</p>
            </td><td>
               <p>6453</p>
            </td><td>
               <p>
                 The port number that Stado will use to allow client processes 
                 to connect to. If you have more than one gs-server running on
                 the same coordinator node (one for development, one for 
                 testing, for example), make sure they use different ports.
               </p>
            </td></tr></tbody></table></div></div><div class="sect2" title="Metadata Database Settings"><div class="titlepage"><div><div><h3 class="title"><a name="metadata_settings"></a>Metadata Database Settings</h3></div></div></div><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td>
               <p><span class="bold"><strong>Configuration Value</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Default</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Description</strong></span></p>
            </td></tr><tr><td>
               <p>xdb.metadata.jdbcdriver</p>
            </td><td>
               <p>org.postgresql.driver.Driver</p>
            </td><td>
               <p>The class name of the JDBC Driver to use with underlying metadata database</p>
            </td></tr><tr><td>
               <p>xdb.metadata.jdbcstring</p>
            </td><td>
               <p>jdbc:postgres://{dbhost}:{dbport}/{database}</p>
            </td><td>
               <p>A template JDBC url to use to connect to the underlying database. </p>
            </td></tr><tr><td>
               <p>xdb.metadata.dbhost</p>
            </td><td>
               <p></p>
            </td><td>
               <p>
                 The host name or IP address or the server that contains the 
                 metadata database. In practice, it will often be the same one
                 as where the Stado server runs.
               </p>
            </td></tr><tr><td>
               <p>xdb.metadata.dbport</p>
            </td><td>
               <p>xdb.default.dbport</p>
            </td><td>
               <p>The port to connect to for the underlying database</p>
            </td></tr><tr><td>
               <p>xdb.metadata.database</p>
            </td><td>
               <p></p>
            </td><td>
               <p>The name of the metadata database, e.g. XDBSYS</p>
            </td></tr><tr><td>
               <p>xdb.metadata.jdbcuser</p>
            </td><td>
               <p></p>
            </td><td>
               <p>The user to use when connecting to the metadata database</p>
            </td></tr><tr><td>
               <p>xdb.metadata.jdbcpassword</p>
            </td><td>
               <p></p>
            </td><td>
               <p>The password to use when connecting to the metadata database</p>
            </td></tr></tbody></table></div></div><div class="sect2" title="JDBC and Pool Settings"><div class="titlepage"><div><div><h3 class="title"><a name="jdbc_settings"></a>JDBC and Pool Settings</h3></div></div></div><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td>
               <p><span class="bold"><strong>Configuration Value</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Default</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Description</strong></span></p>
            </td></tr><tr><td>
               <p>xdb.default.jdbcdriver</p>
            </td><td>
               <p>org.postgresql.driver.Driver</p>
            </td><td>
               <p>The default driver name to use for all connections</p>
            </td></tr><tr><td>
               <p>xdb.default.jdbcstring</p>
            </td><td>
               <p>jdbc:postgres://{dbhost}:{dbport}/{database}</p>
            </td><td>
               <p>The default jdbc url to use for all connections</p>
            </td></tr><tr><td>
               <p>xdb.default.dbport</p>
            </td><td>
               <p>5432</p>
            </td><td>
               <p>The default port to use when connecting to the underlying database.</p>
            </td></tr><tr><td>
               <p>xdb.default.dbusername</p>
            </td><td>
               <p></p>
            </td><td>
               <p>The default username to use for all connections</p>
            </td></tr><tr><td>
               <p>xdb.default.dbpassword</p>
            </td><td>
               <p></p>
            </td><td>
               <p>The default password to use for all connections.</p>
            </td></tr><tr><td>
               <p>xdb.default.threads.pool.initsize</p>
            </td><td>
               <p>5</p>
            </td><td>
               <p>Default thread pool size for all nodes.</p>
            </td></tr><tr><td>
               <p>xdb.default.threads.pool.idle</p>
            </td><td>
               <p>600000</p>
            </td><td>
               <p>Default idle time in milliseconds.</p>
            </td></tr><tr><td>
               <p>xdb.default.threads.pool.maxsize</p>
            </td><td>
               <p>10</p>
            </td><td>
               <p>Default max thread pool size for all nodes.</p>
            </td></tr><tr><td>
               <p>xdb.default.threads.pool.timeout</p>
            </td><td>
               <p>60000</p>
            </td><td>
               <p>Default pool timeout for all nodes in milliseconds.</p>
            </td></tr><tr><td>
               <p>xdb.jdbc.coordinator.pool.initsize</p>
            </td><td>
               <p>xdb.default.threads.pool.initsize</p>
            </td><td>
               <p>The initial size of the coordinator connection pool.</p>
            </td></tr><tr><td>
               <p>xdb.jdbc.coordinator.pool.maxsize</p>
            </td><td>
               <p>xdb.default.threads.pool.maxsize * 0.8</p>
            </td><td>
               <p>The maximum size of the coordinator connection pool</p>
            </td></tr><tr><td>
               <p>xdb.jdbc.pool.maxsize</p>
            </td><td>
               <p>xdb.default.threads.pool.maxsize</p>
            </td><td>
               <p>
                 Maximum number of connections per JDBC pool for underlying 
                 node. Note that this is an important value for managing 
                 simultaneous connections. You may still allow a large number
                 of client connections via xdb.maxconnections, but you might
                 want to limit how many simultaneous queries can execute on the
                 underlying databases at the same time by limiting the pool 
                 here. In addition, depending on your underlying database, you
                 might have licensing restrictions that dictate a smaller pool
                 size. The Stado Scheduler will handle sharing and managing of
                 these pools.
               </p>
            </td></tr><tr><td>
               <p>xdb.jdbc.pool.initsize        </p>
            </td><td>
               <p>xdb.default.threads.pool.initsize</p>
            </td><td>
               <p>Initial JDBC pool size</p>
            </td></tr><tr><td>
               <p>xdb.jdbc.pool.idle</p>
            </td><td>
               <p>xdb.default.threads.pool.idle</p>
            </td><td>
               <p>Default idle timeout value for JDBC Pool, in milliseconds. After this time, connections are released and pool is shrunk.</p>
            </td></tr><tr><td>
               <p>xdb.jdbc.pool.timeout</p>
            </td><td>
               <p>xdb.default.threads.pool.timeout</p>
            </td><td>
               <p>Maximum time to wait for available jdbc connection from pool</p>
            </td></tr><tr><td>
               <p>xdb.jdbc.pool.largequery.count</p>
            </td><td>
               <p>2</p>
            </td><td>
               <p>
                 The number of connections to allow for &#8220;large queries&#8221;. This 
                 allows us to reserve some connections for low-cost commands, 
                 in effect reserving connections for fast operations without 
                 having to have them wait if all connections are being used 
                 executing large queries. This also provides a mechanism for 
                 allowing the DBA to be able to connect and administer the 
                 server if it is very busy.
               </p>
            </td></tr><tr><td>
               <p>xdb.jdbc.pool.largequery.threshold</p>
            </td><td>
               <p>25000</p>
            </td><td>
               <p>The cost at which a query will be designated as a &#8220;long&#8221; query. See xdb.jdbc.largequery.count for more details. </p>
            </td></tr><tr><td>
               <p>xdb.node.n.dbhost</p>
            </td><td>
               <p></p>
            </td><td>
               <p>
                 The host address of the underlying database that the node is 
                 using, where n is the node id. In practice, the host will be 
                 same as the node itself, but that is not required.
               </p>
            </td></tr><tr><td>
               <p>xdb.node.n.dbport</p>
            </td><td>
               <p></p>
            </td><td>
               <p>The default port to use when connecting to the underlying database.</p>
            </td></tr><tr><td>
               <p>xdb.node.n.jdbcdriver</p>
            </td><td>
               <p></p>
            </td><td>
               <p>The JDBC driver to use for node n, where n is the node id.</p>
            </td></tr><tr><td>
               <p>xdb.node.n.jdbcstring</p>
            </td><td>
               <p></p>
            </td><td>
               <p>The JDBC URL template string used to connect to node n, where n is the node id.</p>
            </td></tr><tr><td>
               <p>xdb.node.n.threads.pool.maxsize</p>
            </td><td>
               <p>10</p>
            </td><td>
               <p>Maximum thread execution pool size for node n. In practice, this should be set to the same value as xdb.jdbc.pool.initsize. </p>
            </td></tr><tr><td>
               <p>xdb.node.n.threads.pool.initsize</p>
            </td><td>
               <p>5</p>
            </td><td>
               <p>Initial thread pool size for node id n. </p>
            </td></tr><tr><td>
               <p>xdb.node.n.threads.pool.idle</p>
            </td><td>
               <p>600000</p>
            </td><td>
               <p>In milliseconds, how long to allow a thread to be active with no activity before destroying it.</p>
            </td></tr><tr><td>
               <p>xdb.node.n.threads.pool.timeout</p>
            </td><td>
               <p>60000</p>
            </td><td>
               <p>In milliseconds, how long to wait on an available thread.</p>
            </td></tr><tr><td>
               <p>xdb.nodeFetchSize</p>
            </td><td>
               <p>1000</p>
            </td><td>
               <p>The fetch size to use on the underlying connection.</p>
            </td></tr><tr><td>
               <p>xdb.persist_on_set</p>
            </td><td>
               <p>true</p>
            </td><td>
               <p>
                 If the client connection issues a SET command, persist the 
                 underlying connections. If persisted, these are not available
                 from the pool, and may impact how many concurrent connections
                 available.
               </p>
            </td></tr></tbody></table></div></div><div class="sect2" title="Configuration for Underlying Databases"><div class="titlepage"><div><div><h3 class="title"><a name="under_settings"></a>Configuration for Underlying Databases</h3></div></div></div><p>
         <span class="bold"><strong>Temp Table Handling</strong></span>
       </p><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td>
               <p><span class="bold"><strong>Configuration Value</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Default</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Description</strong></span></p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.createTempTable.start</p>
            </td><td>
               <p>CREATE TEMP TABLE</p>
            </td><td>
               <p>Start of command for CREATE TABLE statement for creating temp table. Allows for alternate syntaxes like &#8220;CREATE TEMP TABLE&#8221;. See also xdb.tempTablePrefix. </p>
               <p></p>
               <p>This is for temp tables that the end user specifies.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.createTempTable.suffix</p>
            </td><td>
               <p>WITHOUT OIDS</p>
            </td><td>
               <p>Suffix to add at the end of CREATE statements for temp tables. This can be used to allow disabling of logging information on the underlying database and greatly improve performance, since temporary tables are used internally by Stado.</p>
               <p></p>
               <p>This is for temp tables that the user specifies.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.createGlobalTempTable.start</p>
            </td><td>
               <p>CREATE TABLE</p>
            </td><td>
               <p>This is used when creating internal temp tables by the database for query processing. </p>
               <p></p>
               <p>Real tables are used, in order to access them across sessions.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.createGlobalTempTable.suffix</p>
            </td><td>
               <p>WITHOUT OIDS</p>
            </td><td>
               <p>The suffix to use when creating an internal temp table used for query processing.</p>
               <p></p>
               <p>Default is an empty string.</p>
            </td></tr><tr><td>
               <p>xdb.tempTablePrefix</p>
            </td><td>
               <p>TMPT</p>
            </td><td>
               <p>Temporary table prefix to use in underlying database. Various databases have different conventions, like &#8220;TEMP.&#8221; or &#8220;#&#8221;. </p>
               <p></p>
               <p>Warning- be careful about assigning. On startup, Stado will try and delete any tables that start with this name, in case permanent tables were used and tables were not cleaned up due to a server error.</p>
            </td></tr><tr><td>
               <p>xdb.allowtemptableindex</p>
            </td><td>
               <p>true</p>
            </td><td>
               <p>Whether or not the underlying database allows the support of indexes on temporary tables.</p>
            </td></tr><tr><td>
               <p>xdb.temporary_intermediate_tables</p>
            </td><td>
               <p>!xdb.use_load_for_step</p>
            </td><td>
               <p>If temporary intermediate tables were used. This is used for INSERT INTO.</p>
            </td></tr><tr><td>
               <p>xdb.tempTableSelect</p>
            </td><td>
               <p>select tablename from pg_tables where tablename LIKE '{xdb.tempTablePrefix}%&#8217;</p>
            </td><td>
               <p>If &#8220;fake&#8221; temp tables are used on the underlying database (instead of actual temp tables), this value can be used to determine how to obtain a list of temp tables on the underlying nodes, to purge any tables at gs-server start-up, in case there are any remaining from previous execution that were not cleaned due to an error.</p>
            </td></tr></tbody></table></div><p>
         <span class="bold"><strong>SQL Command Templates</strong></span>
       </p><p>
         Below are command templates that can be overridden, along with their
         defaults.
       </p><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td>
               <p><span class="bold"><strong>Configuration Value</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Default</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Description</strong></span></p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.addcolumn</p>
            </td><td>
               <p>add {colname}</p>
            </td><td>
               <p>For adding columns within an ALTER TABLE command</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.addprimary</p>
            </td><td>
               <p>alter table {table} add constraint {constr_name} primary key({col_list})</p>
            </td><td>
               <p>For adding a primary key to a table</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.addforeignkey</p>
            </td><td>
               <p>alter table {table} add constraint {constr_name} foreign key ({col_list}) references {reftable}({col_map_list})</p>
            </td><td>
               <p>For adding a foreign key to a table</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.dropcolumn</p>
            </td><td>
               <p>alter table {table} drop {colname}</p>
            </td><td>
               <p>For dropping a column</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.dropconstraint</p>
            </td><td>
               <p>drop constraint {constr_name}</p>
            </td><td>
               <p>Template for dropping a constraint within ALTER TABLE command.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.dropconstraint.check</p>
            </td><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.dropconstraint</p>
            </td><td>
               <p>Template for dropping a check constraint within ALTER TABLE command.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.dropconstraint.primary</p>
            </td><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.dropconstraint</p>
            </td><td>
               <p>Template for dropping a primary key constraint within ALTER TABLE command.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.dropconstraint.reference</p>
            </td><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.dropconstraint</p>
            </td><td>
               <p>Template for dropping a foreign key constraint within ALTER TABLE command.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.dropconstraint.unique</p>
            </td><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.dropconstraint</p>
            </td><td>
               <p>Template for dropping a unique key constraint within ALTER TABLE command.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.dropprimary</p>
            </td><td>
               <p>alter table {table} drop constraint {constr_name}</p>
            </td><td>
               <p>For dropping a primary key from a table</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.modifycolumn</p>
            </td><td>
               <p>alter table {table} alter {colname} type {coltype}</p>
            </td><td>
               <p>For modifying a column&#8217;s type</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.modifycolumn.dropdefault</p>
            </td><td>
               <p>alter {column} drop default</p>
            </td><td>
               <p>Used to indicate that a columns default should be removed</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.modifycolumn.dropnotnull</p>
            </td><td>
               <p>alter {column} drop not null</p>
            </td><td>
               <p>Used to indicate a column should no longer be NOT NULL.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.modifycolumn.setdefault</p>
            </td><td>
               <p>alter {column} set default {default_expr}</p>
            </td><td>
               <p>Used to modify the default value of a column</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.modifycolumn.setnotnull</p>
            </td><td>
               <p>alter {column} set not null</p>
            </td><td>
               <p>Used to indicate a column should be set to not null</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.altertable.modifycolumn.using</p>
            </td><td>
               <p>using {using_expr}</p>
            </td><td>
               <p>An expression for modifying the column</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.altertable</p>
               <p>.settablespace</p>
            </td><td>
               <p>set tablespace {tablespace}</p>
            </td><td>
               <p>Partial command template for setting tablespace</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.altertable</p>
               <p>.settablespace.toparent</p>
            </td><td>
               <p>true</p>
            </td><td>
               <p></p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.analyze.template.table</p>
            </td><td>
               <p>ANALYZE {table}</p>
            </td><td>
               <p>The UPDATE STATISTICS or ANALYZE command template to run on the underlying database to update internal statistics on a table used by the optimizer.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.analyze.template</p>
               <p>.column</p>
            </td><td>
               <p>ANALYZE {table} ({column_list})</p>
            </td><td>
               <p>Other ANALYZE command template when columns are also specified.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.dropindex</p>
            </td><td>
               <p>drop index {index_list}</p>
            </td><td>
               <p>Command to use when dropping indexes</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.renametable.template</p>
               <p> </p>
            </td><td>
               <p>ALTER TABLE {oldname} RENAME TO {newname}</p>
            </td><td>
               <p>Format of command to rename table. </p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.selectinto.template</p>
            </td><td>
               <p>CREATE TABLE {newname} AS SELECT * FROM {oldname}</p>
            </td><td>
               <p>Cammnd to use for SELECT INTO implementation</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.selectintotemp</p>
               <p>.template</p>
            </td><td>
               <p>CREATE TEMP TABLE {newname} AS SELECT * FROM {oldname}</p>
            </td><td>
               <p>Cammnd to use for SELECT INTO implementation when using temp tables</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.updatestatistics.template.table</p>
            </td><td>
               <p>VACUUM ANALYZE {table} </p>
            </td><td>
               <p>The UPDATE STATISTICS or ANALYZE command template to run on the underlying database to update internal statistics on a table used by the optimizer. </p>
               <p></p>
               <p>Example template:</p>
               <p></p>
               <p>UPDATE STATISTICS {table}  </p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.updatestatistics.template.column</p>
            </td><td>
               <p>VACUUM ANALYZE {table} ({column_list})</p>
            </td><td>
               <p>The UPDATE STATISTICS or ANALYZE command template to run on the underlying database to update internal statistics on a table&#8217;s column used by the optimizer. It will process those columns that were explicitly specified in the Stado command. Example template:</p>
               <p></p>
               <p>UPDATE STATISTICS COLUMN {column_list} FOR {table}</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.updatestatistics.query</p>
            </td><td>
               <p>SELECT stadistinct </p>
               <p>FROM pg_statistic s, pg_class c, pg_attribute a </p>
               <p>WHERE s.starelid = c.oid </p>
               <p>AND s.staattnum = a.attnum </p>
               <p>AND c.relname = &#8216;{table}&#8217;</p>
               <p>AND a.attname = &#8216;{column}&#8217;</p>
            </td><td>
               <p>When calculating statistics, the server will try and run the corresponding command on the underlying database, but when finished, it may be able to determine the selectivity from the underlying database without having to resort to calculating it itself. If this parameter is set, it defines a command to obtain the statistics from the underlying database. </p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.update.correlatedstyle</p>
               <p></p>
            </td><td>
               <p>2</p>
            </td><td>
               <p>This is need for the UPDATE command to work properly for correlated updates. </p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand.vacuum.template.table</p>
            </td><td>
               <p>VACUUM {vacuum_type} {table}</p>
            </td><td>
               <p>The command to execute for vacuuming.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.vacuum.analyze.template.table</p>
            </td><td>
               <p>VACUUM {vacuum_type} ANALYZE {table}</p>
            </td><td>
               <p>The command to execute for vacuuming with anaylze.</p>
            </td></tr><tr><td>
               <p>xdb.sqlcommand</p>
               <p>.vacuum.analyze.template.column</p>
            </td><td>
               <p>VACUUM {vacuum_type} ANALYZE {table} ({column_list})</p>
            </td><td>
               <p>The command to execute for vacuuming with analyze with columns specified.</p>
            </td></tr></tbody></table></div><p>
         <span class="bold"><strong>Date and Time Settings</strong></span>
       </p><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td>
               <p><span class="bold"><strong>Configuration Value</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Default</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Description</strong></span></p>
            </td></tr><tr><td>
               <p>xdb.subsecondPrecision</p>
            </td><td>
               <p>0</p>
            </td><td>
               <p>The number of digits for subsecond precision that the underlying database supports.</p>
            </td></tr></tbody></table></div><p>
         <span class="bold"><strong>Other Settings</strong></span>
       </p><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td>
               <p><span class="bold"><strong>Configuration Value</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Default</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Description</strong></span></p>
            </td></tr><tr><td>
               <p>xdb.allow.multistatement.query</p>
            </td><td>
               <p>TRUE</p>
            </td><td>
               <p>If true, allows multiple commands separated by semicolon to be sent together</p>
            </td></tr><tr><td>
               <p>xdb.client_encoding.ignore</p>
            </td><td>
               <p>false</p>
            </td><td>
               <p>client_encoding can only be UNICODE. If this setting is true, then it will not report an error when trying to set to something other than UNICODE. This is to support certain 3rd party apps and drivers. </p>
            </td></tr><tr><td>
               <p>xdb.combined.resultset.buffer</p>
            </td><td>
               <p>1000</p>
            </td><td>
               <p>Default read-ahead buffer per ResultSet when combining</p>
            </td></tr><tr><td>
               <p>xdb.connectiontest.statement</p>
            </td><td>
               <p>select 1</p>
            </td><td>
               <p>Statement to run against backend to verify that connection is still good.</p>
            </td></tr><tr><td>
               <p>xdb.connectiontest.createtable</p>
            </td><td>
               <p></p>
            </td><td>
               <p>Statement to run to (if not null) to create a table to run a query against to test the connection via xdb.connectiontest.statement.</p>
            </td></tr><tr><td>
               <p>xdb.identifier.case</p>
            </td><td>
               <p>lower</p>
            </td><td>
               <p>Default case to use for storing identifier metadata and on the backend databases when unquoted. Other options are &#8220;upper&#8221; and &#8220;preserve&#8221;</p>
            </td></tr><tr><td>
               <p>xdb.identifier.quote</p>
            </td><td>
               <p>"</p>
            </td><td>
               <p>Default quote character for identifiers. This is used for both open and close, unless overridden below.</p>
            </td></tr><tr><td>
               <p>xdb.identifier.quote.open</p>
            </td><td>
               <p></p>
            </td><td>
               <p>Open quote character for identifiers</p>
            </td></tr><tr><td>
               <p>xdb.identifier.quote.close</p>
            </td><td>
               <p></p>
            </td><td>
               <p>Close quote character for identifiers</p>
            </td></tr><tr><td>
               <p>xdb.identifier.quote.escape</p>
            </td><td>
               <p></p>
            </td><td>
               <p>Escape quote character for identifiers</p>
            </td></tr><tr><td>
               <p>xdb.index.useAscDesc</p>
            </td><td>
               <p>false</p>
            </td><td>
               <p>Whether or not it is ok to use ASC or DESC in indexes.</p>
            </td></tr><tr><td>
               <p>xdb.locks.readcommitted.mode</p>
            </td><td>
               <p>S</p>
            </td><td>
               <p>If using an isolation mode of read committed (the default), this can be fine tuned further.</p>
               <p>S (Strict) indicates that only one UPDATE or DELETE statement may be executing at a time per table, which also helps prevent deadlocks. Setting this to L (Loose) allows for concurrent UPDATE and DELETE statements.</p>
            </td></tr><tr><td>
               <p>xdb.max_group_hash_count</p>
            </td><td>
               <p>5</p>
            </td><td>
               <p>How many of the expressions in the group by clause to take into consideration for hashing when aggregating. </p>
            </td></tr><tr><td>
               <p>xdb.savepointType</p>
            </td><td>
               <p>S</p>
            </td><td>
               <p>T = subtransaction, S = Savepoints. Although savepoints from the user&#8217;s point of view is currently not supported, this is used in working with the underlying database.</p>
            </td></tr><tr><td>
               <p>xdb.sort.case.sensitive</p>
            </td><td>
               <p>false</p>
            </td><td>
               <p>Whether or not the underlying database sorts in a case sensitive manner.</p>
            </td></tr><tr><td>
               <p>xdb.sort.nulls.style</p>
            </td><td>
               <p>2</p>
            </td><td>
               <p>How nulls are handled in sorting on the underlying database.</p>
               <p></p>
               <p>0-Nulls always at start</p>
               <p>1-Nulls always at end</p>
               <p>2-Null greater than not null </p>
               <p>3-Null less than not null</p>
            </td></tr><tr><td>
               <p>xdb.sort.trim</p>
            </td><td>
               <p>true</p>
            </td><td>
               <p>Whether or not leading spaces are ignored in sorting</p>
            </td></tr><tr><td>
               <p>xdb.sql.usecrossjoin</p>
            </td><td>
               <p>true</p>
            </td><td>
               <p>Whether or not to use CROSS JOIN syntax for Cartesian products. If overridden to false, syntax used will be &#8220;table1, table2&#8221; instead.</p>
            </td></tr><tr><td>
               <p>xdb.strip_interval_quote</p>
            </td><td>
               <p>true</p>
            </td><td>
               <p>When passing interval constants to the backend, whether or not to quote them in single quotes, such as INTERVAL &#8216;1 day&#8217;.</p>
            </td></tr><tr><td>
               <p>xdb.xrowid.type</p>
               <p> </p>
            </td><td>
               <p>DECIMAL(31,0)   </p>
            </td><td>
               <p>The xrowid settings allow for customization for databases that support varying levels of precision. xrowid is the Stado internal unique tuple identifier.</p>
            </td></tr><tr><td>
               <p>xdb.xrowid.SQLtype</p>
            </td><td>
               <p>3</p>
            </td><td>
               <p>java.sql.Types.DECIMAL</p>
            </td></tr><tr><td>
               <p>xdb.xrowid.length</p>
            </td><td>
               <p>0</p>
            </td><td>
               <p></p>
            </td></tr><tr><td>
               <p>xdb.xrowid.precision</p>
            </td><td>
               <p>31</p>
            </td><td>
               <p></p>
            </td></tr><tr><td>
               <p>xdb.xrowid.scale</p>
            </td><td>
               <p>0</p>
            </td><td>
               <p></p>
            </td></tr></tbody></table></div><p>
         <span class="bold"><strong>Gateway Settings for Administering Underlying Databases</strong></span>
       </p><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td>
               <p><span class="bold"><strong>Configuration Value</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Default</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Description</strong></span></p>
            </td></tr><tr><td>
               <p>xdb.gateway.createdb</p>
            </td><td>
               <p>createdb -h {dbhost} &#8211;p {dbport} -U {dbusername} -O {dbusername} {database} </p>
            </td><td>
               <p>Template command for creating a new database on underlying database</p>
            </td></tr><tr><td>
               <p>xdb.gateway.dropdb</p>
            </td><td>
               <p>dropdb -h {dbhost} -p {dbport} -U {dbusername} {database}</p>
            </td><td>
               <p>Template command for dropping database on nodes</p>
            </td></tr><tr><td>
               <p>xdb.gateway.path</p>
            </td><td>
               <p>null</p>
            </td><td>
               <p>Path to use when trying to execute gateway commands. If not set, it will use whatever is found in user's PATH environment.</p>
            </td></tr><tr><td>
               <p>xdb.gateway.path.separator</p>
            </td><td>
               <p>/</p>
            </td><td>
               <p>The path separator used for gateway commands.</p>
            </td></tr></tbody></table></div><p>
         <span class="bold"><strong>gs-loader settings</strong></span>
       </p><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td>
               <p><span class="bold"><strong>Configuration Value</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Default</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Description</strong></span></p>
            </td></tr><tr><td>
               <p>xdb.loader.dataprocessors.count</p>
            </td><td>
               <p>1</p>
            </td><td>
               <p>The number of processor threads to use internally when performing COPY. Increasing this may help in multi-core/multi-processor systems.</p>
            </td></tr><tr><td>
               <p>xdb.loader.header.columnseparator</p>
            </td><td>
               <p></p>
            </td><td>
               <p>Optional separator for header for output file if exporting.</p>
            </td></tr><tr><td>
               <p>xdb.loader.header.template</p>
            </td><td>
               <p></p>
            </td><td>
               <p>Optional template for output file.</p>
            </td></tr><tr><td>
               <p>xdb.loader.footer.columnseparator</p>
            </td><td>
               <p></p>
            </td><td>
               <p>Optional separator for file footer for output file if exporting.</p>
            </td></tr><tr><td>
               <p>xdb.loader.footer.template</p>
            </td><td>
               <p></p>
            </td><td>
               <p>Optional file footer template if exporting.</p>
            </td></tr><tr><td>
               <p>xdb.loader.intermediate.commit</p>
               <p>.interval</p>
            </td><td>
               <p>0</p>
            </td><td>
               <p>When shipping intermediate results, the commit interval to use, if xdb.use_load_for_step is set to false. If non-zero and used, this should be set fairly high, like 100000.</p>
            </td></tr><tr><td>
               <p>xdb.loader.nodewriter.columninfo</p>
            </td><td>
               <p>({columns})</p>
            </td><td>
               <p>Column info template to use if column names explicitly specified on load</p>
            </td></tr><tr><td>
               <p>xdb.loader.nodewriter.columninfo.</p>
               <p>none</p>
            </td><td>
               <p></p>
            </td><td>
               <p>Template to use if no column names present</p>
            </td></tr><tr><td>
               <p>xdb.loader.nodewriter.delimiterinfo</p>
            </td><td>
               <p>DELIMITER AS '{delimiter}'</p>
            </td><td>
               <p>Template to be used within xdb.loader.nodewrite.template, for specifying passing along delimiter information.</p>
            </td></tr><tr><td>
               <p>xdb.loader.nodewriter.delimiterinfo.none</p>
            </td><td>
               <p>DELIMITER AS '\|\'</p>
            </td><td>
               <p>delimiterinfo template to use when the user did not specify any delimiter. Default null.</p>
            </td></tr><tr><td>
               <p>xdb.loader.nodewriter.template</p>
            </td><td>
               <p>psql -h {dbhost} -p {dbport} -d {database} -U {dbusername} -a -e -E -c \"COPY {table} {columninfo} FROM STDIN WITH NULL AS '' {delimiterinfo}\""</p>
            </td><td>
               <p>This is used for bulk loading data into the underlying database, and describes the template of the command to use. Note that another template, delimiterinfo can be included here. See xdb.loader.</p>
               <p>nodewriter.delimiterinfo for more information</p>
            </td></tr><tr><td>
               <p>xdb.loader.nodewriter.rowdelimiter</p>
            </td><td>
               <p>\n</p>
            </td><td>
               <p>Row separator</p>
            </td></tr><tr><td>
               <p>xdb.loader.nodewriter</p>
               <p>.use_jdbc_copy_api</p>
            </td><td>
               <p>TRUE</p>
            </td><td>
               <p>Indicates if COPY over JDBC should be used when shipping rows.</p>
            </td></tr><tr><td>
               <p>xdb.loader.row.nullvalue</p>
            </td><td>
               <p></p>
            </td><td>
               <p>Null value indicator in loading data</p>
            </td></tr><tr><td>
               <p>xdb.loader.row.quote</p>
            </td><td>
               <p>(none)</p>
            </td><td>
               <p>Indicates that strings are to be quoted with the specified character when loading data.</p>
            </td></tr><tr><td>
               <p>xdb.loader.row.quote.escape</p>
            </td><td>
               <p>(none)</p>
            </td><td>
               <p>Quote escape character</p>
            </td></tr><tr><td>
               <p>xdb.loader.row.template</p>
            </td><td>
               <p>{value_list}</p>
            </td><td>
               <p>Row template for output file</p>
            </td></tr><tr><td>
               <p>xdb.loader.row.columnseparator</p>
            </td><td>
               <p>,</p>
            </td><td>
               <p>The default column separator character to use when loading in data.</p>
            </td></tr><tr><td>
               <p>xdb.use_copy_out_for_step</p>
            </td><td>
               <p>xdb.use_load_for_step</p>
            </td><td>
               <p>When doing row shipping, whether or not to use COPY OUT,to avoid formatting overhead.</p>
            </td></tr><tr><td>
               <p>xdb.use_load_for_step</p>
            </td><td>
               <p>y</p>
            </td><td>
               <p>Indicates if a native database bulk loader utility should be used for handling intermediate results. </p>
            </td></tr><tr><td>
               <p></p>
            </td><td>
               <p></p>
            </td><td>
               <p></p>
            </td></tr></tbody></table></div></div><div class="sect2" title="Data Types and Data Type Mapping"><div class="titlepage"><div><div><h3 class="title"><a name="datatypes"></a>Data Types and Data Type Mapping</h3></div></div></div><p>
       Stado also includes the ability to map SQL data types, to allow for 
       flexibility with various underlying databases, since the different 
       databases sometimes name things differently than standard ANSI. Below
       appears the data types supported and their default mappings, which can
       be overridden in the <code class="literal">stado.config</code> file.
     </p><p>
         <span class="bold"><strong>Numeric types:</strong></span>
       </p><pre class="programlisting">
         xdb.sqltype.integer.map=INT
         xdb.sqltype.smallint.map=SMALLINT
         xdb.sqltype.boolean.map=BOOLEAN
       </pre><p>
         <span class="bold"><strong>Floating point types (parameter "length" available):</strong></span>
       </p><pre class="programlisting">
         xdb.sqltype.float.map=FLOAT ({length})
         xdb.sqltype.real.map=REAL ({length})
         xdb.sqltype.double.map=DOUBLE PRECISION
       </pre><p>
         <span class="bold"><strong>Fixed point types (parameters "precision" and "scale" available):</strong></span>
       </p><pre class="programlisting">
         xdb.sqltype.fixed.map=FIXED ({precision}, {scale})
         xdb.sqltype.numeric.map=NUMERIC ({precision}, {scale})
         xdb.sqltype.decimal.map=DEC ({precision}, {scale})
       </pre><p>
         <span class="bold"><strong>Character types (parameter "length" available):</strong></span>
       </p><pre class="programlisting">
         xdb.sqltype.char.map=CHAR ({length})
         xdb.sqltype.varchar.map=VARCHAR ({length})
         xdb.sqltype.nchar.map=CHAR ({length}) UNICODE
         xdb.sqltype.nvarchar.map=VARCHAR ({length}) UNICODE
       </pre><p>
         <span class="bold"><strong>Date and Time types:</strong></span>
       </p><pre class="programlisting">
         xdb.sqltype.time.map=TIME
         xdb.sqltype.date.map=DATE
         xdb.sqltype.timestamp.map=TIMESTAMP
       </pre><p>
         <span class="bold"><strong>Partitioning</strong></span>
       </p><p>
         Some types of columns can be partitioned on and others cannot be by 
         default. That is because inexact data types like FLOAT can be 
         problematic. Some optional settings allow these to be configured.
       </p><div class="informaltable"><table border="1"><colgroup><col><col><col></colgroup><tbody><tr><td>
               <p><span class="bold"><strong>Configuration Value</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Default</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Description</strong></span></p>
            </td></tr><tr><td>
               <p>xdb.allow.partition.integer</p>
            </td><td>
               <p>true</p>
            </td><td>
               <p>Columns of this type can be the table&#8217;s designated partitioning key</p>
            </td></tr><tr><td>
               <p>xdb.allow.partition.char</p>
            </td><td>
               <p>true</p>
            </td><td>
               <p>Columns of this type can be the table&#8217;s designated partitioning key</p>
            </td></tr><tr><td>
               <p>xdb.allow.partition.decimal</p>
            </td><td>
               <p>true</p>
            </td><td>
               <p>Columns of this type can be the table&#8217;s designated partitioning key</p>
            </td></tr><tr><td>
               <p>xdb.allow.partition.float</p>
            </td><td>
               <p>false</p>
            </td><td>
               <p>Columns of this type can be the table&#8217;s designated partitioning key</p>
            </td></tr><tr><td>
               <p>xdb.allow.partition.datetime</p>
            </td><td>
               <p>false</p>
            </td><td>
               <p>Columns of this type can be the table&#8217;s designated partitioning key</p>
            </td></tr></tbody></table></div></div><div class="sect2" title="Function Mapping"><div class="titlepage"><div><div><h3 class="title"><a name="functions"></a>Function Mapping</h3></div></div></div><p>
       Stado&#8217;s recognized SQL is ANSI-92 in nature, along with the most common
       functions found in most databases, especially PostgreSQL. However, it is
       possible to also use additional functions that are supported by your 
       underlying database when issuing SQL commands. This also includes any 
       stored procedures or user-defined functions used, with the caveat that 
       these should usually not access any tables directly because each will be
       executed in isolation on the particular node.
     </p><p>
       By default, any functions not recognized will be executed on the 
       underlying database directly. In some queries, it is necessary for Stado
       to know the return type.  In those cases, it is best to define these in
       the <code class="literal">stado.config</code> file. 
     </p><p>
       In addition, it is possible to override the definition for a 
       Stado-recognized function and map it to the equivalent function on the 
       underlying database.
     </p><p>
       To either define or override functions, use 
       <code class="literal">xdb.sqlfunction</code>, followed by the function name, 
       followed by following settings.
     </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><tbody><tr><td>
               <p>template</p>
            </td><td>
               <p>Used only if recognized function is being overridden or unknown function is being defined, maps the function to the underlying database</p>
            </td></tr><tr><td>
               <p>returntype</p>
            </td><td>
               <p>The return sql data type of the function</p>
            </td></tr><tr><td>
               <p>paramcount</p>
            </td><td>
               <p>The number of parameters the function takes</p>
            </td></tr><tr><td>
               <p>argn</p>
            </td><td>
               <p>Where n is 1, 2&#8230; the argument</p>
            </td></tr></tbody></table></div><p>
       The SQL data types recognized are:
     </p><pre class="programlisting">
       CHAR, VARCHAR
       DATE, TIME, TIMESTAMP
       BYTE, SMALLINT, INTEGER, BIGINT
       ANYINT, FLOAT, REAL, DOUBLE, NUMERIC, DECIMAL
     </pre><p>
       In addition, ANYCHAR, ANYDATETIME, ANYINT and ANYNUMBER are short-hand 
       notations when more than one type is permissible:
     </p><pre class="programlisting">
       ANYCHAR = CHAR|VARCHAR
       ANYDATETIME = DATE|TIME|TIMESTAMP
       ANYINT = BYTE|SMALLINT|INTEGER|BIGINT
       ANYNUMBER = ANYINT|FLOAT|REAL|DOUBLE|NUMERIC|DECIMAL
     </pre><p>
       For example, to define a function for SUBDATE(date, number_of_days) function:
     </p><pre class="programlisting">
       xdb.sqlfunction.subdate.template=DATE({arg1})-INTERVAL '{arg2} days'
       xdb.sqlfunction.subdate.returntype=DATE
       xdb.sqlfunction.subdate.paramcount=2
       xdb.sqlfunction.subdate.arg1=DATE
       xdb.sqlfunction.subdate.arg2=ANYNUMBER
     </pre></div><div class="sect2" title="Logging"><div class="titlepage"><div><div><h3 class="title"><a name="logging"></a>Logging</h3></div></div></div><p>
       Stado uses a popular library called log4j to implement its logging 
       functionality. More detail can be found online here: 
       http://logging.apache.org/log4j/docs/index.html. 
     </p><p>
       There are a few defined &#8220;loggers&#8221; that are used: console, Server, QUERY,
       and LONGQUERY. The console logger is used for errors and warnings. 
       Server is used for significant server events. QUERY allows you to log 
       all SQL requests to the database, which can be useful in 
       troubleshooting. LONGQUERY allows you to log those requests which seem 
       to be taking a long time to execute, which is useful for a DBA to get
       quickly to the source of which queries seem to be taking the most time 
       to execute.
     </p><p>
       A request is determined to be &#8220;long&#8221; based on another 
       <code class="literal">stado.config</code> value, 
       <code class="literal">xdb.longQuerySeconds</code>, which should be set to the 
       number of seconds at which point it will be logged in the LONGQUERY log.
     </p></div></div></div><div class="chapter" title="Chapter 3. Users and Privileges"><div class="titlepage"><div><div><h2 class="title"><a name="privs"></a>Chapter 3. Users and Privileges</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#users">Users</a></span></dt><dt><span class="sect1"><a href="#privs">Privileges</a></span></dt></dl></div><p>
    Stado supports creation of users and privileges. 
  </p><p>
    It is important to distinguish between users at the Stado level, and those 
    of the underlying databases. Stado does not in turn try and create those 
    same users on the underlying databases. It always accesses the underlying 
    database with the single user defined in the <code class="literal">stado.config</code>
    file. Stado manages its own users and privileges for allowing access to the
    tables.
  </p><div class="sect1" title="Users"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="users"></a>Users</h2></div></div></div><p>
     There are 3 classes of users: DBA, RESOURCE, and STANDARD. DBA users have 
     Database Administration privileges. RESOURCE users can create tables. 
     STANDARD users cannot create tables, but can access the database.
   </p><p>
    Users can be created with the CREATE USER command, and can be modified and 
    dropped with the ALTER USER and DROP USER commands, respectively.
   </p></div><div class="sect1" title="Privileges"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="privs"></a>Privileges</h2></div></div></div><p>
     A user must be granted access to a table before being able to access it.
     By default, a user who creates a table has all privileges on that table.
   </p><p>
     Privileges can be set on tables by using the GRANT and REVOKE commands.
   </p><p>
     More details on using these commands can be found in the Stado SQL 
     Reference manual.
   </p><p>
     The following types of privileges are available:
   </p><pre class="programlisting">
     SELECT
     INSERT
     UPDATE
     DELETE
     REFERENCES
     INDEX
     ALTER
   </pre><p>
     Note that in the current version, Stado does not yet support ROLES.
   </p></div></div><div class="chapter" title="Chapter 4. Redundancy, Backup and Recovery"><div class="titlepage"><div><div><h2 class="title"><a name="backups"></a>Chapter 4. Redundancy, Backup and Recovery</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#redundancy">Redundancy</a></span></dt><dt><span class="sect1"><a href="#load_balancing">Load Balancing</a></span></dt><dt><span class="sect1"><a href="#backups">Backup &amp; Recovery</a></span></dt></dl></div><div class="sect1" title="Redundancy"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="redundancy"></a>Redundancy</h2></div></div></div><p>
     The current version of Stado has no built-in redundancy, but this is a 
     feature that will be added in the near future.  Keep in mind that the 
     component most likely to fail is going to be a hard disk, and by using a
     RAID configuration like RAID 0+1 or RAID-5, you are well protected against
     such a failure.
   </p><p>
     You can achieve a high degree of redundancy, but without automatic 
     failover. Stado will typically be used in reporting or data warehousing
     type of scenarios so while important and will be added, it is not as 
     critical as a high volume OLTP database.
   </p><p>
     One solution is to rely on HA solutions such as from Veritas or Red Hat. 
   </p><p>
     You could have your data out on a SAN, and have a stand-by node ready to
     point to the failed node&#8217;s data. The <code class="literal">stado.config</code> file
     would have to be modified for the node, and Stado stopped and restarted.
   </p><p>
    You can also replicate the metadata database and user-created databases on 
    the nodes.
   </p><p>
    For replication, you can rely on Slony for a manual stand-by configuration.
    Note that any schema changes (<code class="literal">ALTER TABLE</code>) may require 
    re-snapshotting the modified table. To failover to a stand-by node, the 
    node information is changed in <code class="literal">stado.config</code>, and Stado 
    is stopped and restarted.
   </p><p>
    To make efficient use of the nodes in the cluster, you should consider 
    creating the replicated copies of one node on another node. For example, 
    node 1&#8217;s databases are replicated to node 2, node 2&#8217;s to node 3, and so on.
   </p></div><div class="sect1" title="Load Balancing"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="load_balancing"></a>Load Balancing</h2></div></div></div><p>
     Stado provides some amount of &#8220;load balancing&#8221; by virtue of the fact that
     it parallelizes queries and leverages multiple nodes. This allows queries 
     over large amounts of data to execute much faster than they would if they 
     were just on a single system.
   </p><p>
     Also, above, we suggest creating stand-by databases on other nodes in the 
     cluster that are also being used, for efficiency and cost savings, 
     especially if OLTP activity is low.
   </p><p>
     Still, if dedicated replicated standby nodes were created manually in your 
     system and you wish to make use of them for querying for better throughput, 
     it is possible to do so by hand, with some effort, however. (Built-in load 
     balancing is planned for future support.)
   </p><p>
     With the current version, you can execute multiple coordinators while 
     keeping the following in mind:
   </p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
       Your schema should be static. If doing schema changes, you should 
       disable access temporarily to the second cluster until synchronized.
     </li><li class="listitem">
       An IP-based load balancer that supports sticky connections can be 
       used to distribute the load amongst the coordinators.
     </li></ul></div></div><div class="sect1" title="Backup &amp; Recovery"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="backups"></a>Backup &amp; Recovery</h2></div></div></div><p>
     How backups are performed will depend greatly on the underlying database 
     you are using. It is best to rely on the tools of the underlying database 
     to backup nodes. That allows you to do restores on individual nodes and 
     achieve parallelism while performing backups, as opposed to just doing a 
     complete dump of all the data on all the nodes to a single destination. 
   </p><p>
     Many databases have the concept of full backups (backs up everything), 
     incremental backups and log file backups.  This allows for different 
     backup schedules. For example, you may wish to do a complete backup of all 
     of the nodes once a week, and incremental backups every evening, or after 
     a nightly load.
   </p><p>
     If you are in an environment where Stado houses a data warehouse or data 
     mart that where no update or delete activity occurs, with just periodic 
     loads, you can also have a backup schedule with periodic full backups of 
     the database combined with backups of the regular import files.
   </p><p>
     Performing the backups can be done directly on the nodes using the 
     database tools available for the underlying database. Alternatively, the 
     execdb command can be used, which allows for the execution of the (nearly) 
     exact same command on all of the underlying nodes. It makes use of the 
     configuration value set for <code class="literal">stado.config</code> file for the 
     particular database product being used.
   </p><p>
     An example for backing up PostgreSQL locally on each host appears below, 
     assuming a secure environment has been been set up to use ssh (secure shell):
   </p><pre class="programlisting">
     execdb.sh -c "ssh &#8211;h {dbhost} 'pg_dump -h {dbhost} -U {dbusername} {database} 
               -f /data/back/{database}.dump'" -d mydatabase -u stado -p password
   </pre><p>
     To recover a database, there are a couple of scenarios to consider. 
     Typically, the problem will just be on a single node due to a hardware or 
     software failure. If that is the case, use the tools of the underlying 
     database to restore a complete backup if necessary, and any incremental 
     backups and logs, as the case may be. See the documentation for your 
     particular database product for details on how to do this.
   </p><p>
     Another scenario is that a recovery is required because of human error. In 
     this case, all of the nodes may very well be affected and will need to be 
     restored.
   </p></div></div><div class="chapter" title="Chapter 5. Installation"><div class="titlepage"><div><div><h2 class="title"><a name="install"></a>Chapter 5. Installation</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#gs-cmdline">gs-cmdline</a></span></dt><dt><span class="sect1"><a href="#gs-createdb">gs-createdb</a></span></dt><dt><span class="sect1"><a href="#gs-createmddb">gs-createmddb</a></span></dt><dt><span class="sect1"><a href="#gs-dropdb">gs-dropdb</a></span></dt><dt><span class="sect1"><a href="#gs-agent">gs-agent</a></span></dt><dt><span class="sect1"><a href="#gs-dbstart">gs-dbstart</a></span></dt><dt><span class="sect1"><a href="#gs-dbstop">gs-dbstop</a></span></dt><dt><span class="sect1"><a href="#gs-server">gs-server</a></span></dt><dt><span class="sect1"><a href="#gs-shutdown">gs-shutdown</a></span></dt><dt><span class="sect1"><a href="#gs-loader">gs-loader and gs-impex</a></span></dt></dl></div><p>
    In this section, commands used to administer Stado are described.
  </p><p>
    All of these are from classes in the Stado java jar files, but can be 
    accessed more conveniently via the script wrappers in the bin directory. 
    If using Linux or other Unix variant, append a &#8220;.sh&#8221; at the end of the 
    commands listed here. 
  </p><p>
    Note that the scripts invoke java and specify the amount of memory to use 
    for the JVM. In the event that you encounter the OutOfMemoryException, 
    just increase the values specified for &#8211;Xmx.
  </p><div class="sect1" title="gs-cmdline"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="gs-cmdline"></a>gs-cmdline</h2></div></div></div><pre class="programlisting">
    
    gs-cmdline.sh &lt;connect&gt; [-a] [-e] [-t] [-f inputfile] 
    [-o connect_options] [-z]

    &lt;connect&gt; is either a jdbcurl like,
    -j jdbc:postgresql://&lt;host&gt;:&lt;port&gt;/&lt;database&gt;?user=&lt;user&gt;&amp;password=&lt;password&gt;
         or 
   [-h &lt;host&gt;] [-s &lt;port&gt;] -d &lt;database&gt; -u &lt;user&gt; [-p &lt;password&gt;]

    -a : add delimiter. If output mode is NORMAL, it will append an extra delimiter 
         at the end of the last column when doing SELECT queries.
    -e : echo mode. Echoes any statements as it executes them
    -t : has effect of SET OUPUT NORMAL 
        (turns off default table mode)
    -f : input file to be executed, instead of interactive mode.
    -z : display command execution times
    
  </pre><p>
      The <code class="literal">gs-cmdline</code> utility is used to obtain a SQL command 
      prompt and execute SQL commands like CREATE TALBE, SELECT and INSERT 
      interactively. A complete list of SQL commands can be found in the SQL
       Reference manual.  
    </p><p>
      Note that if you have installed PostgreSQL, you can also alternatively 
      use psql. If you use either of these, be sure and include the appropriate 
      Stado port option like &#8211;p 6453. In addition, if executing it on the same 
      server where the coordinator is running, you must use the &#8211;h option to 
      connect via sockets.
    </p><p>
      All commands issued should be terminated with &#8220;;&#8221;. To exit out of 
      <code class="literal">gs-cmdline</code>, use &#8220;exit;&#8221;.
    </p><p>
      There are some additional administrative commands, which appear in the 
      table below that can be used by the DBA.
    </p><div class="informaltable"><table border="1"><colgroup><col><col></colgroup><tbody><tr><td>
               <p><span class="bold"><strong>Command</strong></span></p>
            </td><td>
               <p><span class="bold"><strong>Description</strong></span></p>
            </td></tr><tr><td>
               <p>SHOW DATABASES</p>
            </td><td>
               <p>Lists all of the user-created Stado databases </p>
            </td></tr><tr><td>
               <p>SHOW TABLES</p>
            </td><td>
               <p>Lists all of the tables that exist in the current database</p>
            </td></tr><tr><td>
               <p>SHOW VIEWS</p>
            </td><td>
               <p>Lists all of the views that exist in the current database</p>
            </td></tr><tr><td>
               <p>SHOW TABLE &lt;table&gt;</p>
            </td><td>
               <p>Lists the columns and their definitions of the specified table</p>
            </td></tr><tr><td>
               <p>SHOW VIEW &lt;view&gt;</p>
            </td><td>
               <p>Displays the view definition for the specified view.</p>
            </td></tr><tr><td>
               <p>SHOW INDEXES ON &lt;table&gt;</p>
            </td><td>
               <p>Lists all indexes for &lt;table&gt;</p>
            </td></tr><tr><td>
               <p>SHOW CONSTRAINTS ON &lt;table&gt;</p>
            </td><td>
               <p>Lists the following types of constraints for &lt;table&gt;: primary keys, foreign keys, foreign key references</p>
            </td></tr><tr><td>
               <p>SHOW USERS</p>
            </td><td>
               <p>Lists all defined users and their class</p>
            </td></tr><tr><td>
               <p>SHOW STATEMENTS</p>
            </td><td>
               <p>Lists all of the currently executing SQL statements</p>
            </td></tr><tr><td>
               <p>KILL &lt;request_id&gt;</p>
            </td><td>
               <p>Kills execution of the request id specified. Request ids can be obtained by executing the SHOW STATEMENTS command.</p>
            </td></tr></tbody></table></div></div><div class="sect1" title="gs-createdb"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="gs-createdb"></a>gs-createdb</h2></div></div></div><pre class="programlisting">
     gs-createdb.sh -d dbname
            [-h host] [-s port]
             -u dbusername [-p dbpassword]
             -n nodelist
            [-m]
   </pre><p>
     The <code class="literal">gs-createdb</code> command is used to create Stado 
     databases. 
   </p><p>
     There are two modes of operation, standard and manual. In standard mode it 
     will try and create the physical underlying databases on all of the 
     specified nodes using PostgreSQL&#8217;s createdb command.
   </p><p>
     In manual mode, specified by the &#8211;m option, it will not try and create the 
     underlying databases, but you are required to create them all by hand 
     properly first.
   </p><p>
     Stado uses the naming convention of &lt;dbname&gt;N&lt;nodeid&gt; when 
     naming the actual physical databases on the underlying nodes. So, if you 
     run <code class="literal">gs-createdb</code> in manual mode, you should first create 
     all databases and their names properly before running gs-createdb with &#8211;m 
     to wire it up. This naming scheme means that you could create a logical 
     multi-node system where all nodes are really on the same physical system- 
     this is not recommended of course, but may be helpful in testing.
   </p><p>
     Note that some underlying databases have a limit to the number of 
     characters that can be used when creating the database, so you may need to 
     shorten the name you choose if it is rejected
   </p><p>
     The values of dbusername and dbpassword are used to validate that the user 
     attempting to execute this command is a valid user with administrative 
     (DBA) rights.
   </p><p>
     Note that if you are prompted by a password even with &#8211;p, it is the 
     underlying tool, like psql that is prompting you for a password. This 
     means you are executing <code class="literal">gs-createdb</code> under a user where 
     a trusted PostgreSQL environment has not been configured. Be sure that 
     it is configured for user stado, and execute the command as user stado.
   </p><p>
     The nodelist is a comma-separated list of node ids that must be valid 
     nodes as defined in the <code class="literal">stado.config</code> file.
   </p><p>
     Note: in the current version, if <code class="literal">gs-server</code> is running,
     it must be restarted after <code class="literal">gs-createdb</code> is executed to 
     be able to use the new database and allow users to connect to it.
   </p><p>
     If something goes wrong on one of the nodes during creation (a slightly 
     different configuration on a node, underlying database server not running, 
     etc), it might be easiest to fix the problem as follows: drop the 
     database with the <code class="literal">gs-dropdb.sh</code> command, and then try 
     again to create. If you still have difficulty, retry gs-dropdb.sh with 
     the &#8211;f option.
   </p></div><div class="sect1" title="gs-createmddb"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="gs-createmddb"></a>gs-createmddb</h2></div></div></div><pre class="programlisting">
     gs-createmddb.sh 
           -u dbusername [-p dbpassword]
          [-m]
   </pre><p>
     The <code class="literal">gs-createmddb</code> command creates and initializes the 
     metadata database.
   </p><p>
     It relies on the <code class="literal">xdb.metadata.*</code> values in the 
     <code class="literal">stado.config</code> file being used, so it is important that 
     this file is configured properly before executing. It will try and create 
     the database <code class="literal">xdb.metadata.database</code> on the system 
     <code class="literal">xdb.metadata.dbhost</code> using the command template for 
     <code class="literal">xdb.gateway.createdb</code> (underlying database dependent).
   </p><p>
     After creating the database and running the optional initialization 
     script, <code class="literal">gs-createmddb</code> will create all Stado metadata 
     tables in the metadata database, connecting to it as determined by the 
     <code class="literal">xdb.metadata.*</code> configuration values in the 
     <code class="literal">stado.config</code> file. 
   </p><p>
     Using the &#8220;-m&#8221; option, manual mode, will just try and create the required 
     tables without physically creating the database. This is useful if you 
     want to create the metadata database yourself and then just need to 
     initialize it by creating the required tables.
   </p><p>
     The <code class="literal">gs-createmddb</code> command also creates an initial 
     administrative user used to administer the cluster. As a result, -u 
     followed by a username must be included. If &#8211;p is left off, the user will 
     be prompted for an initial password to be created.
   </p></div><div class="sect1" title="gs-dropdb"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="gs-dropdb"></a>gs-dropdb</h2></div></div></div><pre class="programlisting">
     gs-dropdb.sh -d dbname 
         [-h host] [-s port]
          -u dbusername -p dbpassword [-f]
   </pre><p>
     The <code class="literal">gs-dropdb</code> command is used to drop databases.
   </p><p>
     The dbusername must be a DBA user who has privileges to drop the database.
   </p><p>
     The underlying databases are dropped as defined by the 
     <code class="literal">xdb.gateway.dropdb</code> template in the 
     <code class="literal">stado.config</code> file.
   </p><p>
     If there is a problem dropping the database, retry with the &#8211;f option 
     (force). It will continue to try and remove the metadata from the 
     metadata database even after a failure to remove any underlying databases,
     and will continue to try and drop from all of the underlying nodes, even 
     if it encounters an error on one.
   </p></div><div class="sect1" title="gs-agent"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="gs-agent"></a>gs-agent</h2></div></div></div><pre class="programlisting">
     gs-agent.sh -n nodelist
   </pre><p>
     <code class="literal">gs-agent</code> starts the Stado Agent on a node participating 
     in the cluster that has been installed and configured for agent use.
   </p><p>
     Using <code class="literal">gs-agent</code> on the nodes facilitates better 
     scalability when more nodes are present in the cluster. Instead of the 
     coordinator doing all the work in connecting directly with the underlying 
     databases, each node can be responsible for one.
   </p><p>
     Each agent is started with &#8211;n, followed by its designated node number.
   </p><p>
     Like <code class="literal">gs-server</code>, <code class="literal">gs-agent</code> uses a 
     <code class="literal">stado.config</code> file for its configuration, but it is much
     smaller compared to <code class="literal">gs-server</code>&#8217;s. Once the agent 
     connects to the coordinator, other configuration settings that are needed 
     by the agent will be sent over by the coordinator.
   </p><p>
     It is recommended to start <code class="literal">gs-server</code> on the coordinator 
     before trying to start <code class="literal">gs-agent</code>, but the agent can 
     later be stopped and restarted without having to restart gs-server.
   </p></div><div class="sect1" title="gs-dbstart"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="gs-dbstart"></a>gs-dbstart</h2></div></div></div><pre class="programlisting">
      gs-dbstart.sh -d dbname
          [-h host] [-s socketport] 
           -u dbauser [-p dbapassword]
          [-w waittimeout]
   </pre><p>
     The <code class="literal">gs-dbstart</code> command is used to connect to an 
     existing <code class="literal">gs-server</code> that is already running and bring the
     database dbname online. Internally, it will tell 
     <code class="literal">gs-server</code> to initialize all necessary pools and begin 
     accepting connections for that database.
   </p><p>
     Which <code class="literal">gs-server</code> to connect to is determined by the host
     and port specified. If no host is specified, localhost will be used by 
     default. If no port is specified, 6453 will be used by default.
   </p><p>
     A username and password is required to connect with an existing 
     <code class="literal">gs-server</code> process.
   </p><p>
     An optional waittime may be included to determine how long to wait before 
     failing if a node is inaccessible.
   </p></div><div class="sect1" title="gs-dbstop"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="gs-dbstop"></a>gs-dbstop</h2></div></div></div><pre class="programlisting">
     gs-dbstop.sh -d dbname
          [-h host] [-s socketport] 
           -u dbusername [-p dbpassword]
   </pre><p>
     The <code class="literal">gs-dbstop</code> command is used to connect to an existing 
     <code class="literal">gs-server</code> that is already running and bring the 
     database dbname offline. Internally, it will tell 
     <code class="literal">gs-server</code> to free all related resources and stop 
     accepting connections to that database.
   </p><p>
     The <code class="literal">gs-server</code> to connect to is determined by the host 
     and port arguments. If no host is specified, localhost will be used by 
     default. If no port is specified, 6453 will be used by default.
   </p><p>
     The user and password must be valid for that particular database.
   </p></div><div class="sect1" title="gs-server"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="gs-server"></a>gs-server</h2></div></div></div><pre class="programlisting">
     gs-server.sh [-d database_list]  [-x]
   </pre><p>
     <code class="literal">gs-server</code> is executed to start Stado.
   </p><p>
     The main configuration for the server appears in its corresponding 
     <code class="literal">stado.config</code> file, which is found in 
     <code class="literal">$GSPATH/config</code>. Please see &#8220;The 
     <code class="literal">stado.config</code> File&#8221; section under Configuration in this
     document for more details.
   </p><p>
     When starting the <code class="literal">gs-server</code>, a space-separated list of 
     databases to bring online may be included with the &#8211;d option. A database 
     must be brought online before clients can connect to it. If there already
     is an <code class="literal">gs-server</code> instance running, Stado databases can 
     also be brought online with the <code class="literal">gs-dbstart</code> command.
   </p><p>
     The &#8211;x option indicates that all of those Stado user databases specified
     in the database list should be brought online on the underlying nodes. 
   </p><p>
     Note that when executing the <code class="literal">gs-server</code> process, you may 
     need to modify the parameters that Java uses, increasing the maximum amount
     of memory specified in the gs-server.sh launch script.
   </p></div><div class="sect1" title="gs-shutdown"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="gs-shutdown"></a>gs-shutdown</h2></div></div></div><pre class="programlisting">
     gs-shutdown.sh [-h host ] [-s socketport] 
                -u dbusername -p dbpassword
               [-d dblist]
   </pre><p>
     <code class="literal">gs-shutdown</code> is executed to shutdown a Stado 
     (<code class="literal">gs-server</code>) process. It is not to be confused with
     <code class="literal">gs-dbstop</code>, which merely brings a database offline, 
     while allowing the gs-server process to continue executing.
   </p><p>
     The <code class="literal">gs-server</code> to connect to is determined by the host 
     and port specified. If no host is specified, localhost will be used by 
     default. If no port is specified, 6453 will be used by default.
   </p><p>
     The user and password must be valid for that particular database.
   </p></div><div class="sect1" title="gs-loader and gs-impex"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="gs-loader"></a>gs-loader and gs-impex</h2></div></div></div><p>
     The <code class="literal">gs-impex</code> utility allows for the importing and 
     exporting of data, while <code class="literal">gs-loader</code> is targeted
     exclusively for loading data.
   </p><p>
     There is a separate document, the Stado Import and Export Utilities 
     manual, which provides more detail about using these commands.
   </p></div></div><div class="chapter" title="Chapter 6. Isolation Levels and Locking"><div class="titlepage"><div><div><h2 class="title"><a name="isolation"></a>Chapter 6. Isolation Levels and Locking</h2></div></div></div><p>
    The four standard isolation levels are
  </p><pre class="programlisting">
    SERIALIZABLE 
    REPEATABLE READ 
    READ COMMITTED
    READ UNCOMMITTED
  </pre><p>
    By default, Stado uses Read Committed mode (a transaction only sees those 
    rows from the beginning of the transaction until it completes). The ANSI 
    SQL standard allows for a more restrictive isolation level than the one 
    specified, and Stado treats Read Uncommitted as Read Committed and 
    Repeatable Read as Serializable.
  </p><p>
    Furthermore, even in Read Committed mode, by default Stado will use an 
    exclusive table lock for Update and Delete statements. This can be 
    overridden with the <code class="literal">stado.config</code> setting 
    <code class="literal">xdb.locks.readcommitted.mode</code>. It is set to &#8220;S&#8221; (strict) 
    by default, but can be overridden to &#8220;L&#8221; (loose), allowing for shared 
    write locks on tables
  </p><p>
    If your particular environment does not have a lot of update activity, 
    the default should work adequately. Using mode &#8220;L&#8221; is useful for ETL 
    processes where multiple threads are used to update the same table, which
    will result in much better performance. The downside of using mode &#8220;L&#8221; is 
    the added risk that a deadlock may occur across nodes if multiple client 
    sessions are updating the same rows in a transaction.
  </p></div><div class="chapter" title="Chapter 7. Troubleshooting"><div class="titlepage"><div><div><h2 class="title"><a name="troubleshooting"></a>Chapter 7. Troubleshooting</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#install">Issues with Installation and Configuration</a></span></dt><dt><span class="sect1"><a href="#execution">Issues with Execution</a></span></dt></dl></div><p>
    This section covers issues that you may encounter while using your Stado 
    cluster, and offers possible solutions.
  </p><div class="sect1" title="Issues with Installation and Configuration"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="install"></a>Issues with Installation and Configuration</h2></div></div></div><p>
     <span class="bold"><strong>
       The script <code class="literal">gs-createmddb.sh</code> appears to hang
     </strong></span>
   </p><p>
     This is due to a missing or misconfigured <code class="literal">.pgpass</code> or 
     <code class="literal">pgpass.conf</code> file. Correct the problem, and try again.
   </p><p>
     <span class="bold"><strong>
       &#8220;Template in use&#8221; error when running <code class="literal">gs-createmddb.sh</code>
       or <code class="literal">gs-createdb.sh</code>
     </strong></span>
   </p><p>
     This is an error message from the underlying PostgreSQL database server,
     and is caused when trying to create a new database when the template 
     database is believed to be in use. Restart PostgreSQL, and try again.
   </p></div><div class="sect1" title="Issues with Execution"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="execution"></a>Issues with Execution</h2></div></div></div><p>
     <span class="bold"><strong>
Connections, Pooling, and Timeouts
     </strong></span>
   </p><p>
     Stado utilizes various thread and connection pools, and depending on their 
     settings and your workload, you may encounter a timeout issue.
   </p><p>
     For the client connecting to the Stado server, keep in mind that there is 
     a fixed limit to the maximum number of client connections. This is 
     configured in the <code class="literal">stado.config</code> file via the 
     <code class="literal">xdb.maxconnections</code> setting, where you can override the 
     default setting.
   </p><p>
     Stado in turn uses pooled connections for communicating with the 
     underlying databases on the nodes. The number of connections used for 
     each node is determined via <code class="literal">xdb.jdbc.pool.initsize</code> and 
     <code class="literal">xdb.jdbc.pool.maxsize</code>. You may also have to change the 
     settings in the underlying database that you are using to accept more 
     connections, if you use large values here.
   </p><p>
     If the number of client connections is larger than these pools, the 
     requests will remain on the request queue for a longer period of time. 
     (Even if the number of requests is smaller than the pools, some 
     &#8220;expensive&#8221; requests may be not be executed right away by the scheduler to
     try and both maximize throughput and be responsive for less expensive 
     requests.)
   </p><p>
     In addition to the pool sizes, the pools have timeouts. If an executing 
     request cannot obtain the needed connections after the time specified in 
     milliseconds by <code class="literal">xdb.jdbc.pool.timeout</code>, the request 
     will timeout.
   </p><p>
     Closely related to the JDBC pools are the thread pools, with settings 
     <code class="literal">xdb.default.threads.pool.maxsize</code>, 
     <code class="literal">xdb.default.threads.pool.initsize</code>, 
     <code class="literal">xdb.default.threads.pool.timeout</code>. A request will only 
     be executed if there are enough threads available in the pool. Normally 
     the thread pool and jdbc pools should have the same size values.
   </p><p>
     You may also receive timeouts under very heavy query loads with many 
     concurrent sessions. You can try increasing the values of 
     <code class="literal">xdb.messagemonitor.timeout.millis</code> and 
     <code class="literal">xdb.messagemonitor.timeout.short.millis</code>.
   </p><p>
     <span class="bold"><strong>
       &#8220;Cannot send data to nodes&#8221; error message
     </strong></span>
   </p><p>
     If you receive the &#8220;cannot send data to nodes&#8221; error message, it is likely
     that you have run into a memory resource issue. Try modifying the 
     <code class="literal">gs-server.sh</code> script, increasing the values for 
     MAXMEMORY and MINMEMORY, setting them both to the same value.
   </p><p>
     Also, ensure that <code class="literal">/etc/security/limits.conf</code> has been 
     changed to increase the nofile setting.
   </p><p>
     If the problem is encountered only when there is a heavy load after 
     modifying the above, there may not be enough memory to handle your load. 
     In that case, reduce the number of concurrent queries that can execute 
     simultaneously, by reducing thread and connection pools. The default for 
     <code class="literal">xdb.default.threads.pool.maxsize</code> (10) should be quite
     safe, but if you overrode this substantially, you should throttle it back
     down. Note that more statements (and client connections) can be accepted
     by Stado, it will just prioritize and queue them up, while limiting the 
     number of concurrently executing queries.
   </p><p>
     If, however, you see this error message for even the simplest queries, 
     there probably is a permissions issue between the nodes. Make sure 
     permissions are setup properly, including the .pgpass file and the 
     usernames and passwords used. 
   </p><p>
     If the problem persists, there may be a resource problem or a problem
     with the underlying PostgreSQL database. Please check system logs (e.g., 
     <code class="literal">/var/log/syslog</code>) and PostgreSQL log files.
   </p><p>
     <span class="bold"><strong>
       OutOfMemory Exception
     </strong></span>
   </p><p>
     If you encounter this, you have run into a memory resource issue. Try 
     modifying the <code class="literal">gs-server.sh</code> script, increasing the 
     values for  MAXMEMORY and MINMEMORY, setting them both to the same value.
   </p><p>
     <span class="bold"><strong>
       Concurrent Performance Slow
     </strong></span>
   </p><p>
     The intended usage for Stado is in a data-warehousing environment where 
     heavy transaction activity is expected. Nonetheless, Stado still can 
     process hundreds of low-cost statements per second over multiple client 
     sessions.
   </p><p>
     For an individual session, Stado does add an extra hop and therefore 
     latency. So, a single session will be much slower compared to a native 
     PostgreSQL database for example. Keep in mind that individual session 
     performance and total throughput are different things; over many sessions 
     working concurrently, much greater total throughput can be achieved.
   </p><p>
     Please also read the chapter on isolation levels and locking. In 
     particular, you can modify the setting 
     <code class="literal">xdb.locks.readcommitted.mode</code> in the 
     <code class="literal">stado.config</code> file, setting it to &#8220;L&#8221;.
   </p></div></div><div class="chapter" title="Chapter 8. Appendices"><div class="titlepage"><div><div><h2 class="title"><a name="appendices"></a>Chapter 8. Appendices</h2></div></div></div><div class="toc"><p><b>Table of Contents</b></p><dl><dt><span class="sect1"><a href="#metadata_schema">Metadata Database Schema</a></span></dt></dl></div><div class="sect1" title="Metadata Database Schema"><div class="titlepage"><div><div><h2 class="title" style="clear: both"><a name="metadata_schema"></a>Metadata Database Schema</h2></div></div></div><pre class="programlisting">
create table xsystablespaces (
 tablespaceid int not null,
 tablespacename varchar(255) not null,
 ownerid int not null,
 primary key(tablespaceid)
)
;
create unique index idx_xsystablespaces_1
 on xsystablespaces (tablespacename)
;
create table xsystablespacelocs (
 tablespacelocid int not null,
 tablespaceid int not null,
 filepath varchar(1024) not null,
 nodeid int not null,
 primary key(tablespacelocid)
)
;
create unique index idx_xsystablespacelocs_1
 on xsystablespacelocs (tablespaceid, nodeid)
;
alter table xsystablespacelocs
 add foreign key (tablespaceid) references xsystablespaces (tablespaceid)
;
create table xsysusers (
  userid int not null,
  username char(30) not null,
  userpwd char(32) not null,
  usertype char(8) not null, 
  primary key (userid)
)
;
create unique index idx_xsysusers_1 on xsysusers (username)
;
create table xsysdatabases
(
 dbid int not null,
 dbname varchar(128) not null,
 primary key (dbid)
) 
;
create unique index idx_xsysdatabases_1
 on xsysdatabases (dbname)
;
create table xsysdbnodes
(
 dbnodeid int not null,
 dbid int not null,
 nodeid int not null,
 primary key (dbid, nodeid)
)
;
create unique index idxnodes1 on xsysdbnodes (dbnodeid)
;
alter table xsysdbnodes
 add foreign key (dbid) references xsysdatabases (dbid)
;
create table xsystables
(
 tableid int not null,
 dbid integer not null,
 tablename char(255) not null,
 numrows int not null,
 partscheme smallint not null, 
 partcol char(255),    
 parthash int,
 owner int,
 parented int,
 tablespaceid int,
 clusteridx varchar(80),
 primary key (tableid)
)
;
alter table xsystables
 add foreign key (dbid) references xsysdatabases (dbid)
;
alter table xsystables
 add foreign key (parentid) references xsystables (tableid)
;        
alter table xsystables
 add foreign key (tablespaceid) references xsystablespaces (tablespaceid)
;
create table xsystabparts
(
 partid int not null,
 tableid integer not null,
 dbid integer not null,
 nodeid int not null,
 primary key (partid)
)
;
alter table xsystabparts
 add foreign key (tableid) references xsystables (tableid)
;
alter table xsystabparts
 add foreign key (dbid, nodeid) references xsysdbnodes (dbid, nodeid)
;
create table xsystabparthash
(
 parthashid int not null,
 tableid integer not null,
 dbid integer not null,
 hashvalue integer not null,
 nodeid int not null,
 primary key (parthashid)
)
;
alter table xsystabparthash
 add foreign key (tableid) references xsystables (tableid)
;
alter table xsystabparthash
 add foreign key (dbid, nodeid) references xsysdbnodes (dbid, nodeid)
;

create table xsyscolumns
(
 colid serial,
 tableid int not null,
 colseq smallint not null,
 colname varchar(255) not null,
 coltype smallint not null,
 collength int,
 colscale smallint,
 colprecision smallint,
 isnullable smallint not null,
 isserial smallint,
 defaultexpr varchar(255),
 checkexpr varchar(255),
 selectivity float,
 nativecoldef varchar(255), 
 primary key (colid)
)
;
alter table xsyscolumns
 add foreign key (tableid) references xsystables (tableid)
;
create unique index idx_xsyscolumns_1
 on xsyscolumns (tableid, colseq)
;
create table xsysindexes
(
 idxid int not null,
 idxname varchar(80) not null,
 tableid int not null,
 keycnt smallint not null,
 idxtype char(1),  
 tablespaceid int, 
 issyscreated smallint not null,
 primary key (idxid)
)
;
alter table xsysindexes
 add foreign key (tableid) references xsystables (tableid)
;
alter table xsysindexes
 add foreign key (tablespaceid) references xsystablespaces (tablespaceid)
;
create table xsysindexkeys
(
 idxkeyid int not null,
 idxid int not null,
 idxkeyseq int not null,
 idxascdesc smallint not null, 
 colid int not null,
 primary key (idxkeyid)
)
;
alter table xsysindexkeys
 add foreign key (idxid) references xsysindexes (idxid)
;
alter table xsysindexkeys
 add foreign key (colid) references xsyscolumns (colid)
;
create unique index idx_xsysindexkeys_1
 on xsysindexkeys (idxid, idxkeyseq)
;
;
create table xsysconstraints
(
 constid int not null,
 constname varchar(128),  
 tableid int not null,
 consttype char(1) not null, 
 idxid int,
 issoft smallint not null,
 primary key (constid)
)
;
alter table xsysconstraints
 add foreign key (tableid) references xsystables (tableid)
;
alter table xsysconstraints
 add foreign key (idxid) references xsysindexes (idxid)
;
create table xsysreferences
(
 refid int not null,
 constid int not null,
 reftableid int not null,
 refidxid int not null,  
 primary key (refid)
)
;
alter table xsysreferences
 add foreign key (constid) references xsysconstraints (constid)
;
alter table xsysreferences
 add foreign key (reftableid) references xsystables (tableid)
;
alter table xsysreferences
 add foreign key (refidxid) references xsysindexes (idxid)
;
;
create table xsysforeignkeys
(
 fkeyid int not null,
 refid int not null,
 fkeyseq int not null,
 colid int not null,
 refcolid int not null,
 primary key (fkeyid)
)
;
alter table xsysforeignkeys
 add foreign key (refid) references xsysreferences (refid)
;
alter table xsysforeignkeys
 add foreign key (colid) references xsyscolumns (colid)
;
alter table xsysforeignkeys
 add foreign key (refcolid) references xsyscolumns (colid)
;
create unique index idx_xsysforeignkeys_1
 on xsysforeignkeys (refid, fkeyseq)
;
create table xsystabprivs (
 privid int not null,
 userid int,
 tableid int not null,
 selectpriv char(1) not null,
 insertpriv char(1) not null,
 updatepriv char(1) not null,
 deletepriv char(1) not null,
 referencespriv char(1) not null,
 indexpriv char(1) not null,
 alterpriv char(1) not null,
 primary key (privid)
)
;
alter table xsystabprivs
 add foreign key (userid) references xsysusers (userid)
;
alter table xsystabprivs
 add foreign key (tableid) references xsystables (tableid)
;
create unique index idx_xsystabprivs_1
 on xsystabprivs (userid, tableid)
;
alter table xsystables
 add foreign key (owner) references xsysusers (userid)
;
create table xsysviews ( 
 viewid int not null, 
 dbid int not null, 
 viewname varchar(255), 
 viewtext varchar(7500))
;
create unique index idx_xsysviews_1 
 on xsysviews (viewid)
;
alter table xsysviews 
 add foreign key (dbid) references xsysdatabases (dbid)
;
create table xsysviewscolumns (
 viewcolid int not null, 
 viewid int not null,
 viewcolseqno int not null,
 viewcolumn varchar(255),
 coltype smallint not null,
 collength int,
 colscale smallint,
 colprecision smallint, 
 primary key (viewcolid))
;
create unique index idx_sysviewscols_1 
 on xsysviewscolumns (viewid, viewcolseqno)
;
alter table xsysviewscolumns 
 add foreign key (viewid) references xsysviews (viewid)
;
create table xsysviewdeps   ( 
 viewid int not null, 
 columnid int not null, 
 tableid int not null) 
;
alter table xsysviewdeps 
 add foreign key (viewid) references xsysviews (viewid)
;
create table xsyschecks (
 checkid int not null,
 constid int not null,
 seqno int not null,
 checkstmt varchar(8000), 
primary key (checkid))
;
create unique index idx_xsyschecks_1
 on xsyschecks (constid, seqno)
;
alter table xsyschecks
add foreign key (constid) references xsysconstraints (constid)
;
    </pre></div></div></div></body></html>
